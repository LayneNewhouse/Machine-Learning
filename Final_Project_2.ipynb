{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data, test_classifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit, RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import randint\n",
    "from scipy import stats\n",
    "from time import time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    enron_data = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = []\n",
    "zeros = []\n",
    "pois = []\n",
    "for person in enron_data:\n",
    "    zero = 0\n",
    "    pois.append(enron_data[person]['poi'])\n",
    "    for key in enron_data[person]:\n",
    "        value = enron_data[person][key]\n",
    "        if value == (0 or 'NaN'):\n",
    "            zero += 1\n",
    "    names.append(person)\n",
    "    zeros.append(zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  6.,  43.,  16.,  12.,  10.,  24.,   6.,  18.,  10.,   1.]),\n",
       " array([  2. ,   3.8,   5.6,   7.4,   9.2,  11. ,  12.8,  14.6,  16.4,\n",
       "         18.2,  20. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAECCAYAAAAB2kexAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvzMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10604d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_true = []\n",
    "poi_false = []\n",
    "for i in range(0, len(zeros)):\n",
    "    if pois[i] == True:\n",
    "        poi_true.append(zeros[i])\n",
    "    else:\n",
    "        poi_false.append(zeros[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAECCAYAAAAxVlaQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIuIhhbeIiIcU3iIiHvp/X6yvNu5MQTgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb9993c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "binwidth = 1\n",
    "bins= range(min(poi_false), max(poi_false) + binwidth, binwidth)\n",
    "\n",
    "plt.hist(poi_true, bins, alpha=0.5, label='POI')\n",
    "plt.hist(poi_false, bins, alpha=0.5, label='Non POI')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xticks(np.arange(min(poi_false), max(poi_false)+1, 1.0))\n",
    "plt.xlim(0, 22)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOWRY CHARLES P\n",
      "WALTERS GARETH W\n",
      "CHAN RONNIE\n",
      "WODRASKA JOHN\n",
      "URQUHART JOHN A\n",
      "WHALEY DAVID A\n",
      "MENDELSOHN JOHN\n",
      "CLINE KENNETH W\n",
      "WAKEHAM JOHN\n",
      "DUNCAN JOHN H\n",
      "LEMAISTRE CHARLES\n",
      "WROBEL BRUCE\n",
      "MEYER JEROME J\n",
      "SCRIMSHAW MATTHEW\n",
      "GATHMANN WILLIAM D\n",
      "GILLIS JOHN\n",
      "LOCKHART EUGENE E\n",
      "PEREIRA PAULO V. FERRAZ\n",
      "BLAKE JR. NORMAN P\n",
      "GRAY RODNEY\n",
      "THE TRAVEL AGENCY IN THE PARK\n",
      "NOLES JAMES L\n",
      "CHRISTODOULOU DIOMEDES\n",
      "WINOKUR JR. HERBERT S\n",
      "BADUM JAMES P\n",
      "YEAP SOON\n",
      "FUGH JOHN L\n",
      "SAVAGE FRANK\n",
      "GRAMM WENDY L\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bonus': 97343619,\n",
       " 'deferral_payments': 32083396,\n",
       " 'deferred_income': -27992891,\n",
       " 'director_fees': 1398517,\n",
       " 'email_address': 'NaN',\n",
       " 'exercised_stock_options': 311764000,\n",
       " 'expenses': 5235198,\n",
       " 'from_messages': 'NaN',\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'loan_advances': 83925000,\n",
       " 'long_term_incentive': 48521928,\n",
       " 'other': 42667589,\n",
       " 'poi': False,\n",
       " 'restricted_stock': 130322299,\n",
       " 'restricted_stock_deferred': -7576788,\n",
       " 'salary': 26704229,\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'total_payments': 309886585,\n",
       " 'total_stock_value': 434509511}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0, len(zeros)):\n",
    "    if zeros[i] > 14:\n",
    "        enron_data.pop(names[i], 0)\n",
    "        print names[i]\n",
    "        \n",
    "enron_data.pop(\"TOTAL\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enron_df = pd.DataFrame.from_dict(enron_data, \"index\")\n",
    "\n",
    "financial_features = ['salary', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus',\n",
    "                      'restricted_stock_deferred', 'deferred_income', 'total_stock_value', 'expenses',\n",
    "                      'exercised_stock_options', 'other', 'long_term_incentive', 'restricted_stock', 'director_fees']\n",
    "removed_financial_features = ['deferral_payments', 'loan_advances', 'restricted_stock_deferred', 'director_fees']\n",
    "\n",
    "financial_features = [feature for feature in financial_features if feature not in removed_financial_features]\n",
    "financial_df = enron_df[financial_features]\n",
    "financial_df = financial_df.replace(\"NaN\", 0)\n",
    "financial_df[\"bonus_over_salary\"] = financial_df[\"bonus\"] / financial_df[\"salary\"]\n",
    "financial_df[\"stock_value_over_salary\"] = financial_df[\"total_stock_value\"] / financial_df[\"salary\"]\n",
    "\n",
    "financial_df = financial_df.drop(\"exercised_stock_options\", 1)\n",
    "\n",
    "financial_df = financial_df.apply(abs).apply(add_one).apply(np.log10)\n",
    "\n",
    "email_features = ['to_messages', 'from_poi_to_this_person', 'from_messages', \n",
    "                  'from_this_person_to_poi', 'shared_receipt_with_poi']\n",
    "\n",
    "email_df = enron_df[email_features]\n",
    "email_df = email_df.replace(\"NaN\", 0)\n",
    "email_df[\"received_from_poi_over_toal_received\"] = email_df[\"from_poi_to_this_person\"] / email_df[\"to_messages\"]\n",
    "email_df[\"sent_to_poi_over_toal_sent\"] = email_df[\"from_this_person_to_poi\"] / email_df[\"from_messages\"]\n",
    "\n",
    "\n",
    "features_df = financial_df.join(email_df).join(enron_df[\"poi\"])\n",
    "features_df[\"payments_over_sent_poi_ratio\"] = financial_df[\"total_payments\"] / email_df[\"sent_to_poi_over_toal_sent\"]\n",
    "features_df[\"payments_over_received_poi_ratio\"] = financial_df[\"total_payments\"] / email_df[\"received_from_poi_over_toal_received\"]\n",
    "\n",
    "features_df = features_df.replace([\"inf\",\"-inf\", \"NaN\"], 0)\n",
    "dataset = features_df.to_dict(orient='index')\n",
    "\n",
    "labels_df = enron_df[\"poi\"]\n",
    "\n",
    "feature_list = []\n",
    "feature_list = features_df.columns.tolist()\n",
    "#move poi to front of list for tester.py\n",
    "feature_list.insert(0, feature_list.pop(feature_list.index('poi')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_one(array):\n",
    "    new_array = [x+1 for x in array]\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>expenses</th>\n",
       "      <th>other</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>bonus_over_salary</th>\n",
       "      <th>stock_value_over_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALLEN PHILLIP K</th>\n",
       "      <td>5.305257</td>\n",
       "      <td>6.651709</td>\n",
       "      <td>6.620657</td>\n",
       "      <td>6.488700</td>\n",
       "      <td>6.237931</td>\n",
       "      <td>4.142045</td>\n",
       "      <td>2.184691</td>\n",
       "      <td>5.484024</td>\n",
       "      <td>5.100467</td>\n",
       "      <td>1.335917</td>\n",
       "      <td>0.980639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANNANTINE JAMES M</th>\n",
       "      <td>2.679428</td>\n",
       "      <td>5.961989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.707996</td>\n",
       "      <td>6.719620</td>\n",
       "      <td>4.750524</td>\n",
       "      <td>5.936777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.244908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.041141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>5.426679</td>\n",
       "      <td>6.750843</td>\n",
       "      <td>6.079182</td>\n",
       "      <td>6.141781</td>\n",
       "      <td>7.026258</td>\n",
       "      <td>4.049257</td>\n",
       "      <td>6.424931</td>\n",
       "      <td>6.200319</td>\n",
       "      <td>6.595795</td>\n",
       "      <td>0.739783</td>\n",
       "      <td>1.610365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAY FRANKLIN R</th>\n",
       "      <td>5.379617</td>\n",
       "      <td>5.917871</td>\n",
       "      <td>5.602061</td>\n",
       "      <td>5.304581</td>\n",
       "      <td>4.799444</td>\n",
       "      <td>5.111071</td>\n",
       "      <td>1.845098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163749</td>\n",
       "      <td>0.426341</td>\n",
       "      <td>0.101375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAZELIDES PHILIP J</th>\n",
       "      <td>4.907513</td>\n",
       "      <td>5.934568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.204023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.942008</td>\n",
       "      <td>4.971976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.317920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BECK SALLY W</th>\n",
       "      <td>5.364234</td>\n",
       "      <td>5.986355</td>\n",
       "      <td>5.845099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.100467</td>\n",
       "      <td>4.570228</td>\n",
       "      <td>2.753583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.100467</td>\n",
       "      <td>0.604872</td>\n",
       "      <td>0.188870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BELDEN TIMOTHY N</th>\n",
       "      <td>5.330414</td>\n",
       "      <td>6.740491</td>\n",
       "      <td>6.720159</td>\n",
       "      <td>6.368182</td>\n",
       "      <td>6.045599</td>\n",
       "      <td>4.239450</td>\n",
       "      <td>5.323662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.197474</td>\n",
       "      <td>1.407099</td>\n",
       "      <td>0.791707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BELFER ROBERT</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.010728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.644379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERBERIAN DAVID</th>\n",
       "      <td>5.335624</td>\n",
       "      <td>5.358839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.396830</td>\n",
       "      <td>4.075291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.939130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.097379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERGSIEKER RICHARD P</th>\n",
       "      <td>5.273980</td>\n",
       "      <td>5.791586</td>\n",
       "      <td>5.397942</td>\n",
       "      <td>5.686470</td>\n",
       "      <td>5.819050</td>\n",
       "      <td>4.772146</td>\n",
       "      <td>5.630750</td>\n",
       "      <td>5.255878</td>\n",
       "      <td>5.819050</td>\n",
       "      <td>0.367419</td>\n",
       "      <td>0.653993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BHATNAGAR SANJAY</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.189105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.139454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.415723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIBI PHILIPPE A</th>\n",
       "      <td>5.329654</td>\n",
       "      <td>6.311244</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.265718</td>\n",
       "      <td>4.586137</td>\n",
       "      <td>5.629092</td>\n",
       "      <td>5.567875</td>\n",
       "      <td>5.577587</td>\n",
       "      <td>0.754432</td>\n",
       "      <td>0.983675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLACHMAN JEREMY M</th>\n",
       "      <td>5.395409</td>\n",
       "      <td>6.304240</td>\n",
       "      <td>5.929419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.979710</td>\n",
       "      <td>4.925359</td>\n",
       "      <td>2.436163</td>\n",
       "      <td>5.920024</td>\n",
       "      <td>5.276558</td>\n",
       "      <td>0.645411</td>\n",
       "      <td>0.684823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOWEN JR RAYMOND M</th>\n",
       "      <td>5.444984</td>\n",
       "      <td>6.426445</td>\n",
       "      <td>6.130334</td>\n",
       "      <td>2.921166</td>\n",
       "      <td>5.401497</td>\n",
       "      <td>4.818938</td>\n",
       "      <td>3.210051</td>\n",
       "      <td>5.988690</td>\n",
       "      <td>5.401497</td>\n",
       "      <td>0.766832</td>\n",
       "      <td>0.279830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BROWN MICHAEL</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.692750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.692750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUCHANAN HAROLD G</th>\n",
       "      <td>5.394483</td>\n",
       "      <td>6.023103</td>\n",
       "      <td>5.698971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.006255</td>\n",
       "      <td>2.778874</td>\n",
       "      <td>3.084934</td>\n",
       "      <td>5.484024</td>\n",
       "      <td>5.276558</td>\n",
       "      <td>0.479430</td>\n",
       "      <td>0.706758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUTTS ROBERT H</th>\n",
       "      <td>5.417500</td>\n",
       "      <td>6.104345</td>\n",
       "      <td>5.875062</td>\n",
       "      <td>4.875067</td>\n",
       "      <td>5.620781</td>\n",
       "      <td>3.973636</td>\n",
       "      <td>5.177989</td>\n",
       "      <td>5.243041</td>\n",
       "      <td>5.620781</td>\n",
       "      <td>0.587474</td>\n",
       "      <td>0.414458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUY RICHARD B</th>\n",
       "      <td>5.519233</td>\n",
       "      <td>6.372121</td>\n",
       "      <td>5.954243</td>\n",
       "      <td>5.841899</td>\n",
       "      <td>6.537123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.602682</td>\n",
       "      <td>5.886413</td>\n",
       "      <td>5.955042</td>\n",
       "      <td>0.570866</td>\n",
       "      <td>1.057687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CALGER CHRISTOPHER F</th>\n",
       "      <td>5.380555</td>\n",
       "      <td>6.214658</td>\n",
       "      <td>6.096910</td>\n",
       "      <td>5.419131</td>\n",
       "      <td>5.100467</td>\n",
       "      <td>4.554113</td>\n",
       "      <td>2.687529</td>\n",
       "      <td>5.574384</td>\n",
       "      <td>5.100467</td>\n",
       "      <td>0.792688</td>\n",
       "      <td>0.183184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARTER REBECCA C</th>\n",
       "      <td>5.417986</td>\n",
       "      <td>5.679026</td>\n",
       "      <td>5.477123</td>\n",
       "      <td>5.203558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.733197</td>\n",
       "      <td>4.875067</td>\n",
       "      <td>5.487565</td>\n",
       "      <td>0.331604</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAUSEY RICHARD A</th>\n",
       "      <td>5.618247</td>\n",
       "      <td>6.271553</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.371070</td>\n",
       "      <td>6.398298</td>\n",
       "      <td>4.486785</td>\n",
       "      <td>5.488404</td>\n",
       "      <td>5.544069</td>\n",
       "      <td>6.398298</td>\n",
       "      <td>0.532569</td>\n",
       "      <td>0.846728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLWELL WESLEY</th>\n",
       "      <td>5.460211</td>\n",
       "      <td>6.173287</td>\n",
       "      <td>6.079182</td>\n",
       "      <td>5.158552</td>\n",
       "      <td>5.844007</td>\n",
       "      <td>4.217879</td>\n",
       "      <td>5.007496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.844007</td>\n",
       "      <td>0.712552</td>\n",
       "      <td>0.534013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORDES WILLIAM R</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.016275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.586965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COX DAVID</th>\n",
       "      <td>5.497329</td>\n",
       "      <td>6.041943</td>\n",
       "      <td>5.903091</td>\n",
       "      <td>4.615434</td>\n",
       "      <td>5.695161</td>\n",
       "      <td>4.445012</td>\n",
       "      <td>2.694605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.577587</td>\n",
       "      <td>0.549670</td>\n",
       "      <td>0.411115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CUMBERLAND MICHAEL S</th>\n",
       "      <td>5.266937</td>\n",
       "      <td>5.907388</td>\n",
       "      <td>5.511885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.317940</td>\n",
       "      <td>4.349180</td>\n",
       "      <td>2.853698</td>\n",
       "      <td>5.439334</td>\n",
       "      <td>5.317940</td>\n",
       "      <td>0.440550</td>\n",
       "      <td>0.327280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEFFNER JOSEPH M</th>\n",
       "      <td>5.314124</td>\n",
       "      <td>6.082301</td>\n",
       "      <td>5.778152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.201976</td>\n",
       "      <td>4.619375</td>\n",
       "      <td>4.407459</td>\n",
       "      <td>5.525498</td>\n",
       "      <td>5.151780</td>\n",
       "      <td>0.592278</td>\n",
       "      <td>0.248565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DELAINEY DAVID W</th>\n",
       "      <td>5.562488</td>\n",
       "      <td>6.676509</td>\n",
       "      <td>6.477121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.558020</td>\n",
       "      <td>4.935381</td>\n",
       "      <td>3.220631</td>\n",
       "      <td>6.112264</td>\n",
       "      <td>6.121609</td>\n",
       "      <td>0.964519</td>\n",
       "      <td>1.037333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DERRICK JR. JAMES V</th>\n",
       "      <td>5.692297</td>\n",
       "      <td>5.741137</td>\n",
       "      <td>5.903091</td>\n",
       "      <td>6.108565</td>\n",
       "      <td>6.946055</td>\n",
       "      <td>4.708633</td>\n",
       "      <td>3.874076</td>\n",
       "      <td>5.684846</td>\n",
       "      <td>6.252217</td>\n",
       "      <td>0.419093</td>\n",
       "      <td>1.277320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DETMERING TIMOTHY J</th>\n",
       "      <td>5.323254</td>\n",
       "      <td>6.080837</td>\n",
       "      <td>5.628390</td>\n",
       "      <td>5.889437</td>\n",
       "      <td>6.307039</td>\n",
       "      <td>4.718136</td>\n",
       "      <td>3.043755</td>\n",
       "      <td>5.618736</td>\n",
       "      <td>5.498406</td>\n",
       "      <td>0.479863</td>\n",
       "      <td>1.026679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIETRICH JANET R</th>\n",
       "      <td>5.398115</td>\n",
       "      <td>6.149362</td>\n",
       "      <td>5.778152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.270699</td>\n",
       "      <td>3.541080</td>\n",
       "      <td>2.675778</td>\n",
       "      <td>5.745400</td>\n",
       "      <td>5.498406</td>\n",
       "      <td>0.531356</td>\n",
       "      <td>0.927235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAI LOU L</th>\n",
       "      <td>5.418102</td>\n",
       "      <td>6.494625</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.376904</td>\n",
       "      <td>4.505801</td>\n",
       "      <td>6.262322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.927050</td>\n",
       "      <td>0.682917</td>\n",
       "      <td>1.963552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PICKERING MARK R</th>\n",
       "      <td>5.816266</td>\n",
       "      <td>6.141980</td>\n",
       "      <td>5.477123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.459377</td>\n",
       "      <td>4.500429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163754</td>\n",
       "      <td>0.018685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIPER GREGORY F</th>\n",
       "      <td>5.294669</td>\n",
       "      <td>6.239957</td>\n",
       "      <td>5.602061</td>\n",
       "      <td>4.522887</td>\n",
       "      <td>5.944626</td>\n",
       "      <td>4.634054</td>\n",
       "      <td>2.891537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.612312</td>\n",
       "      <td>0.481374</td>\n",
       "      <td>0.737703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIRO JIM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.674907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.674907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POWERS WILLIAM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.243063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRENTICE JAMES</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.751548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.039430</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.319751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REDMOND BRIAN L</th>\n",
       "      <td>4.986059</td>\n",
       "      <td>5.047392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.897095</td>\n",
       "      <td>4.167022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.581251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.916338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REYNOLDS LAWRENCE</th>\n",
       "      <td>4.883093</td>\n",
       "      <td>5.596021</td>\n",
       "      <td>5.000004</td>\n",
       "      <td>5.301032</td>\n",
       "      <td>6.625507</td>\n",
       "      <td>3.924796</td>\n",
       "      <td>5.305465</td>\n",
       "      <td>5.193823</td>\n",
       "      <td>5.304241</td>\n",
       "      <td>0.363408</td>\n",
       "      <td>1.750208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RICE KENNETH D</th>\n",
       "      <td>5.623907</td>\n",
       "      <td>5.703335</td>\n",
       "      <td>6.243038</td>\n",
       "      <td>6.544612</td>\n",
       "      <td>7.353003</td>\n",
       "      <td>4.671645</td>\n",
       "      <td>5.242641</td>\n",
       "      <td>6.208713</td>\n",
       "      <td>6.439074</td>\n",
       "      <td>0.712681</td>\n",
       "      <td>1.737125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RIEKER PAULA H</th>\n",
       "      <td>5.396552</td>\n",
       "      <td>6.041038</td>\n",
       "      <td>5.845099</td>\n",
       "      <td>5.000004</td>\n",
       "      <td>6.283050</td>\n",
       "      <td>4.522079</td>\n",
       "      <td>3.290257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.452783</td>\n",
       "      <td>0.580808</td>\n",
       "      <td>0.939527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHANKMAN JEFFREY A</th>\n",
       "      <td>5.483032</td>\n",
       "      <td>6.482688</td>\n",
       "      <td>6.301030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.316397</td>\n",
       "      <td>5.252805</td>\n",
       "      <td>3.076276</td>\n",
       "      <td>5.743841</td>\n",
       "      <td>5.799436</td>\n",
       "      <td>0.879473</td>\n",
       "      <td>0.892842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAPIRO RICHARD S</th>\n",
       "      <td>5.429877</td>\n",
       "      <td>6.024300</td>\n",
       "      <td>5.812914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.994318</td>\n",
       "      <td>5.139148</td>\n",
       "      <td>2.848805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.578828</td>\n",
       "      <td>0.533476</td>\n",
       "      <td>0.669141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHARP VICTORIA T</th>\n",
       "      <td>5.394709</td>\n",
       "      <td>6.197697</td>\n",
       "      <td>5.778152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.693847</td>\n",
       "      <td>5.065722</td>\n",
       "      <td>3.380573</td>\n",
       "      <td>5.625476</td>\n",
       "      <td>5.328510</td>\n",
       "      <td>0.533763</td>\n",
       "      <td>0.475862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHELBY REX</th>\n",
       "      <td>5.326018</td>\n",
       "      <td>6.301873</td>\n",
       "      <td>5.301032</td>\n",
       "      <td>3.619928</td>\n",
       "      <td>6.396830</td>\n",
       "      <td>4.359551</td>\n",
       "      <td>6.196818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.939130</td>\n",
       "      <td>0.288717</td>\n",
       "      <td>1.106225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHERRICK JEFFREY B</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.263037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.608526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHERRIFF JOHN R</th>\n",
       "      <td>5.632236</td>\n",
       "      <td>6.637028</td>\n",
       "      <td>6.176092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.495403</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.267685</td>\n",
       "      <td>5.743841</td>\n",
       "      <td>6.111741</td>\n",
       "      <td>0.653048</td>\n",
       "      <td>0.918942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SKILLING JEFFREY K</th>\n",
       "      <td>6.045815</td>\n",
       "      <td>6.938656</td>\n",
       "      <td>6.748188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.416535</td>\n",
       "      <td>4.467416</td>\n",
       "      <td>4.344844</td>\n",
       "      <td>6.283301</td>\n",
       "      <td>6.835289</td>\n",
       "      <td>0.780989</td>\n",
       "      <td>1.388833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABLER FRANK</th>\n",
       "      <td>5.379311</td>\n",
       "      <td>6.046139</td>\n",
       "      <td>5.698971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.709045</td>\n",
       "      <td>4.217879</td>\n",
       "      <td>5.551538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.709045</td>\n",
       "      <td>0.489630</td>\n",
       "      <td>0.496467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SULLIVAN-SHAKLOVITZ COLLEEN</th>\n",
       "      <td>5.211601</td>\n",
       "      <td>5.999721</td>\n",
       "      <td>5.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.134297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.212188</td>\n",
       "      <td>5.743841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207992</td>\n",
       "      <td>0.971715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUNDE MARTIN</th>\n",
       "      <td>5.410755</td>\n",
       "      <td>6.188945</td>\n",
       "      <td>5.845099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.844428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.045804</td>\n",
       "      <td>5.678019</td>\n",
       "      <td>5.844428</td>\n",
       "      <td>0.570379</td>\n",
       "      <td>0.569889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAYLOR MITCHELL S</th>\n",
       "      <td>5.423598</td>\n",
       "      <td>6.038487</td>\n",
       "      <td>5.778152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.573458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.751124</td>\n",
       "      <td>0.513527</td>\n",
       "      <td>1.179576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THORN TERENCE H</th>\n",
       "      <td>5.346537</td>\n",
       "      <td>5.959735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.682848</td>\n",
       "      <td>4.664134</td>\n",
       "      <td>5.630051</td>\n",
       "      <td>5.301032</td>\n",
       "      <td>5.562675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.355886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TILNEY ELIZABETH A</th>\n",
       "      <td>5.393293</td>\n",
       "      <td>5.601402</td>\n",
       "      <td>5.477123</td>\n",
       "      <td>5.759669</td>\n",
       "      <td>6.067459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.182004</td>\n",
       "      <td>5.439334</td>\n",
       "      <td>5.761020</td>\n",
       "      <td>0.344965</td>\n",
       "      <td>0.757582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMANOFF ADAM S</th>\n",
       "      <td>5.460281</td>\n",
       "      <td>6.053256</td>\n",
       "      <td>5.896940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.725283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.572073</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALLS JR ROBERT H</th>\n",
       "      <td>5.552780</td>\n",
       "      <td>6.254978</td>\n",
       "      <td>5.929419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.770778</td>\n",
       "      <td>4.707033</td>\n",
       "      <td>0.477121</td>\n",
       "      <td>5.732998</td>\n",
       "      <td>6.191019</td>\n",
       "      <td>0.528961</td>\n",
       "      <td>1.243524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WASAFF GEORGE</th>\n",
       "      <td>5.414968</td>\n",
       "      <td>6.014687</td>\n",
       "      <td>5.511885</td>\n",
       "      <td>5.765911</td>\n",
       "      <td>6.313114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.154120</td>\n",
       "      <td>5.301032</td>\n",
       "      <td>5.589020</td>\n",
       "      <td>0.352186</td>\n",
       "      <td>0.949851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WESTFAHL RICHARD K</th>\n",
       "      <td>4.804446</td>\n",
       "      <td>5.882032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.033464</td>\n",
       "      <td>5.585383</td>\n",
       "      <td>4.714925</td>\n",
       "      <td>5.603286</td>\n",
       "      <td>5.408566</td>\n",
       "      <td>5.585383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.847492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHALLEY LAWRENCE G</th>\n",
       "      <td>5.707881</td>\n",
       "      <td>6.670021</td>\n",
       "      <td>6.477121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.783842</td>\n",
       "      <td>4.762221</td>\n",
       "      <td>5.478605</td>\n",
       "      <td>5.907598</td>\n",
       "      <td>6.446565</td>\n",
       "      <td>0.837472</td>\n",
       "      <td>1.110972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHITE JR THOMAS E</th>\n",
       "      <td>5.501804</td>\n",
       "      <td>6.286537</td>\n",
       "      <td>5.653213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.180244</td>\n",
       "      <td>4.910379</td>\n",
       "      <td>6.035615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.141358</td>\n",
       "      <td>0.383300</td>\n",
       "      <td>1.687454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAGER F SCOTT</th>\n",
       "      <td>5.199766</td>\n",
       "      <td>5.556665</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.074990</td>\n",
       "      <td>4.731975</td>\n",
       "      <td>5.170118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.553423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.880977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               salary  total_payments     bonus  \\\n",
       "ALLEN PHILLIP K              5.305257        6.651709  6.620657   \n",
       "BANNANTINE JAMES M           2.679428        5.961989  0.000000   \n",
       "BAXTER JOHN C                5.426679        6.750843  6.079182   \n",
       "BAY FRANKLIN R               5.379617        5.917871  5.602061   \n",
       "BAZELIDES PHILIP J           4.907513        5.934568  0.000000   \n",
       "BECK SALLY W                 5.364234        5.986355  5.845099   \n",
       "BELDEN TIMOTHY N             5.330414        6.740491  6.720159   \n",
       "BELFER ROBERT                0.000000        5.010728  0.000000   \n",
       "BERBERIAN DAVID              5.335624        5.358839  0.000000   \n",
       "BERGSIEKER RICHARD P         5.273980        5.791586  5.397942   \n",
       "BHATNAGAR SANJAY             0.000000        7.189105  0.000000   \n",
       "BIBI PHILIPPE A              5.329654        6.311244  6.000000   \n",
       "BLACHMAN JEREMY M            5.395409        6.304240  5.929419   \n",
       "BOWEN JR RAYMOND M           5.444984        6.426445  6.130334   \n",
       "BROWN MICHAEL                0.000000        4.692750  0.000000   \n",
       "BUCHANAN HAROLD G            5.394483        6.023103  5.698971   \n",
       "BUTTS ROBERT H               5.417500        6.104345  5.875062   \n",
       "BUY RICHARD B                5.519233        6.372121  5.954243   \n",
       "CALGER CHRISTOPHER F         5.380555        6.214658  6.096910   \n",
       "CARTER REBECCA C             5.417986        5.679026  5.477123   \n",
       "CAUSEY RICHARD A             5.618247        6.271553  6.000000   \n",
       "COLWELL WESLEY               5.460211        6.173287  6.079182   \n",
       "CORDES WILLIAM R             0.000000        0.000000  0.000000   \n",
       "COX DAVID                    5.497329        6.041943  5.903091   \n",
       "CUMBERLAND MICHAEL S         5.266937        5.907388  5.511885   \n",
       "DEFFNER JOSEPH M             5.314124        6.082301  5.778152   \n",
       "DELAINEY DAVID W             5.562488        6.676509  6.477121   \n",
       "DERRICK JR. JAMES V          5.692297        5.741137  5.903091   \n",
       "DETMERING TIMOTHY J          5.323254        6.080837  5.628390   \n",
       "DIETRICH JANET R             5.398115        6.149362  5.778152   \n",
       "...                               ...             ...       ...   \n",
       "PAI LOU L                    5.418102        6.494625  6.000000   \n",
       "PICKERING MARK R             5.816266        6.141980  5.477123   \n",
       "PIPER GREGORY F              5.294669        6.239957  5.602061   \n",
       "PIRO JIM                     0.000000        0.000000  0.000000   \n",
       "POWERS WILLIAM               0.000000        0.000000  0.000000   \n",
       "PRENTICE JAMES               0.000000        5.751548  0.000000   \n",
       "REDMOND BRIAN L              4.986059        5.047392  0.000000   \n",
       "REYNOLDS LAWRENCE            4.883093        5.596021  5.000004   \n",
       "RICE KENNETH D               5.623907        5.703335  6.243038   \n",
       "RIEKER PAULA H               5.396552        6.041038  5.845099   \n",
       "SHANKMAN JEFFREY A           5.483032        6.482688  6.301030   \n",
       "SHAPIRO RICHARD S            5.429877        6.024300  5.812914   \n",
       "SHARP VICTORIA T             5.394709        6.197697  5.778152   \n",
       "SHELBY REX                   5.326018        6.301873  5.301032   \n",
       "SHERRICK JEFFREY B           0.000000        0.000000  0.000000   \n",
       "SHERRIFF JOHN R              5.632236        6.637028  6.176092   \n",
       "SKILLING JEFFREY K           6.045815        6.938656  6.748188   \n",
       "STABLER FRANK                5.379311        6.046139  5.698971   \n",
       "SULLIVAN-SHAKLOVITZ COLLEEN  5.211601        5.999721  5.000004   \n",
       "SUNDE MARTIN                 5.410755        6.188945  5.845099   \n",
       "TAYLOR MITCHELL S            5.423598        6.038487  5.778152   \n",
       "THORN TERENCE H              5.346537        5.959735  0.000000   \n",
       "TILNEY ELIZABETH A           5.393293        5.601402  5.477123   \n",
       "UMANOFF ADAM S               5.460281        6.053256  5.896940   \n",
       "WALLS JR ROBERT H            5.552780        6.254978  5.929419   \n",
       "WASAFF GEORGE                5.414968        6.014687  5.511885   \n",
       "WESTFAHL RICHARD K           4.804446        5.882032  0.000000   \n",
       "WHALLEY LAWRENCE G           5.707881        6.670021  6.477121   \n",
       "WHITE JR THOMAS E            5.501804        6.286537  5.653213   \n",
       "YEAGER F SCOTT               5.199766        5.556665  0.000000   \n",
       "\n",
       "                             deferred_income  total_stock_value  expenses  \\\n",
       "ALLEN PHILLIP K                     6.488700           6.237931  4.142045   \n",
       "BANNANTINE JAMES M                  3.707996           6.719620  4.750524   \n",
       "BAXTER JOHN C                       6.141781           7.026258  4.049257   \n",
       "BAY FRANKLIN R                      5.304581           4.799444  5.111071   \n",
       "BAZELIDES PHILIP J                  0.000000           6.204023  0.000000   \n",
       "BECK SALLY W                        0.000000           5.100467  4.570228   \n",
       "BELDEN TIMOTHY N                    6.368182           6.045599  4.239450   \n",
       "BELFER ROBERT                       0.000000           4.644379  0.000000   \n",
       "BERBERIAN DAVID                     0.000000           6.396830  4.075291   \n",
       "BERGSIEKER RICHARD P                5.686470           5.819050  4.772146   \n",
       "BHATNAGAR SANJAY                    0.000000           0.000000  0.000000   \n",
       "BIBI PHILIPPE A                     0.000000           6.265718  4.586137   \n",
       "BLACHMAN JEREMY M                   0.000000           5.979710  4.925359   \n",
       "BOWEN JR RAYMOND M                  2.921166           5.401497  4.818938   \n",
       "BROWN MICHAEL                       0.000000           0.000000  4.692750   \n",
       "BUCHANAN HAROLD G                   0.000000           6.006255  2.778874   \n",
       "BUTTS ROBERT H                      4.875067           5.620781  3.973636   \n",
       "BUY RICHARD B                       5.841899           6.537123  0.000000   \n",
       "CALGER CHRISTOPHER F                5.419131           5.100467  4.554113   \n",
       "CARTER REBECCA C                    5.203558           0.000000  0.000000   \n",
       "CAUSEY RICHARD A                    5.371070           6.398298  4.486785   \n",
       "COLWELL WESLEY                      5.158552           5.844007  4.217879   \n",
       "CORDES WILLIAM R                    0.000000           6.016275  0.000000   \n",
       "COX DAVID                           4.615434           5.695161  4.445012   \n",
       "CUMBERLAND MICHAEL S                0.000000           5.317940  4.349180   \n",
       "DEFFNER JOSEPH M                    0.000000           5.201976  4.619375   \n",
       "DELAINEY DAVID W                    0.000000           6.558020  4.935381   \n",
       "DERRICK JR. JAMES V                 6.108565           6.946055  4.708633   \n",
       "DETMERING TIMOTHY J                 5.889437           6.307039  4.718136   \n",
       "DIETRICH JANET R                    0.000000           6.270699  3.541080   \n",
       "...                                      ...                ...       ...   \n",
       "PAI LOU L                           0.000000           7.376904  4.505801   \n",
       "PICKERING MARK R                    0.000000           4.459377  4.500429   \n",
       "PIPER GREGORY F                     4.522887           5.944626  4.634054   \n",
       "PIRO JIM                            0.000000           4.674907  0.000000   \n",
       "POWERS WILLIAM                      4.243063           0.000000  0.000000   \n",
       "PRENTICE JAMES                      0.000000           6.039430  0.000000   \n",
       "REDMOND BRIAN L                     0.000000           6.897095  4.167022   \n",
       "REYNOLDS LAWRENCE                   5.301032           6.625507  3.924796   \n",
       "RICE KENNETH D                      6.544612           7.353003  4.671645   \n",
       "RIEKER PAULA H                      5.000004           6.283050  4.522079   \n",
       "SHANKMAN JEFFREY A                  0.000000           6.316397  5.252805   \n",
       "SHAPIRO RICHARD S                   0.000000           5.994318  5.139148   \n",
       "SHARP VICTORIA T                    0.000000           5.693847  5.065722   \n",
       "SHELBY REX                          3.619928           6.396830  4.359551   \n",
       "SHERRICK JEFFREY B                  0.000000           6.263037  0.000000   \n",
       "SHERRIFF JOHN R                     0.000000           6.495403  0.000000   \n",
       "SKILLING JEFFREY K                  0.000000           7.416535  4.467416   \n",
       "STABLER FRANK                       0.000000           5.709045  4.217879   \n",
       "SULLIVAN-SHAKLOVITZ COLLEEN         0.000000           6.134297  0.000000   \n",
       "SUNDE MARTIN                        0.000000           5.844428  0.000000   \n",
       "TAYLOR MITCHELL S                   0.000000           6.573458  0.000000   \n",
       "THORN TERENCE H                     0.000000           6.682848  4.664134   \n",
       "TILNEY ELIZABETH A                  5.759669           6.067459  0.000000   \n",
       "UMANOFF ADAM S                      0.000000           0.000000  4.725283   \n",
       "WALLS JR ROBERT H                   0.000000           6.770778  4.707033   \n",
       "WASAFF GEORGE                       5.765911           6.313114  0.000000   \n",
       "WESTFAHL RICHARD K                  4.033464           5.585383  4.714925   \n",
       "WHALLEY LAWRENCE G                  0.000000           6.783842  4.762221   \n",
       "WHITE JR THOMAS E                   0.000000           7.180244  4.910379   \n",
       "YEAGER F SCOTT                      0.000000           7.074990  4.731975   \n",
       "\n",
       "                                other  long_term_incentive  restricted_stock  \\\n",
       "ALLEN PHILLIP K              2.184691             5.484024          5.100467   \n",
       "BANNANTINE JAMES M           5.936777             0.000000          6.244908   \n",
       "BAXTER JOHN C                6.424931             6.200319          6.595795   \n",
       "BAY FRANKLIN R               1.845098             0.000000          5.163749   \n",
       "BAZELIDES PHILIP J           2.942008             4.971976          0.000000   \n",
       "BECK SALLY W                 2.753583             0.000000          5.100467   \n",
       "BELDEN TIMOTHY N             5.323662             0.000000          5.197474   \n",
       "BELFER ROBERT                0.000000             0.000000          0.000000   \n",
       "BERBERIAN DAVID              0.000000             0.000000          5.939130   \n",
       "BERGSIEKER RICHARD P         5.630750             5.255878          5.819050   \n",
       "BHATNAGAR SANJAY             5.139454             0.000000          6.415723   \n",
       "BIBI PHILIPPE A              5.629092             5.567875          5.577587   \n",
       "BLACHMAN JEREMY M            2.436163             5.920024          5.276558   \n",
       "BOWEN JR RAYMOND M           3.210051             5.988690          5.401497   \n",
       "BROWN MICHAEL                0.000000             0.000000          0.000000   \n",
       "BUCHANAN HAROLD G            3.084934             5.484024          5.276558   \n",
       "BUTTS ROBERT H               5.177989             5.243041          5.620781   \n",
       "BUY RICHARD B                5.602682             5.886413          5.955042   \n",
       "CALGER CHRISTOPHER F         2.687529             5.574384          5.100467   \n",
       "CARTER REBECCA C             2.733197             4.875067          5.487565   \n",
       "CAUSEY RICHARD A             5.488404             5.544069          6.398298   \n",
       "COLWELL WESLEY               5.007496             0.000000          5.844007   \n",
       "CORDES WILLIAM R             0.000000             0.000000          5.586965   \n",
       "COX DAVID                    2.694605             0.000000          5.577587   \n",
       "CUMBERLAND MICHAEL S         2.853698             5.439334          5.317940   \n",
       "DEFFNER JOSEPH M             4.407459             5.525498          5.151780   \n",
       "DELAINEY DAVID W             3.220631             6.112264          6.121609   \n",
       "DERRICK JR. JAMES V          3.874076             5.684846          6.252217   \n",
       "DETMERING TIMOTHY J          3.043755             5.618736          5.498406   \n",
       "DIETRICH JANET R             2.675778             5.745400          5.498406   \n",
       "...                               ...                  ...               ...   \n",
       "PAI LOU L                    6.262322             0.000000          6.927050   \n",
       "PICKERING MARK R             0.000000             0.000000          0.000000   \n",
       "PIPER GREGORY F              2.891537             0.000000          5.612312   \n",
       "PIRO JIM                     0.000000             0.000000          4.674907   \n",
       "POWERS WILLIAM               0.000000             0.000000          0.000000   \n",
       "PRENTICE JAMES               0.000000             0.000000          5.319751   \n",
       "REDMOND BRIAN L              0.000000             0.000000          5.581251   \n",
       "REYNOLDS LAWRENCE            5.305465             5.193823          5.304241   \n",
       "RICE KENNETH D               5.242641             6.208713          6.439074   \n",
       "RIEKER PAULA H               3.290257             0.000000          5.452783   \n",
       "SHANKMAN JEFFREY A           3.076276             5.743841          5.799436   \n",
       "SHAPIRO RICHARD S            2.848805             0.000000          5.578828   \n",
       "SHARP VICTORIA T             3.380573             5.625476          5.328510   \n",
       "SHELBY REX                   6.196818             0.000000          5.939130   \n",
       "SHERRICK JEFFREY B           0.000000             0.000000          5.608526   \n",
       "SHERRIFF JOHN R              6.267685             5.743841          6.111741   \n",
       "SKILLING JEFFREY K           4.344844             6.283301          6.835289   \n",
       "STABLER FRANK                5.551538             0.000000          5.709045   \n",
       "SULLIVAN-SHAKLOVITZ COLLEEN  2.212188             5.743841          0.000000   \n",
       "SUNDE MARTIN                 5.045804             5.678019          5.844428   \n",
       "TAYLOR MITCHELL S            0.000000             0.000000          5.751124   \n",
       "THORN TERENCE H              5.630051             5.301032          5.562675   \n",
       "TILNEY ELIZABETH A           5.182004             5.439334          5.761020   \n",
       "UMANOFF ADAM S               0.000000             0.000000          0.000000   \n",
       "WALLS JR ROBERT H            0.477121             5.732998          6.191019   \n",
       "WASAFF GEORGE                3.154120             5.301032          5.589020   \n",
       "WESTFAHL RICHARD K           5.603286             5.408566          5.585383   \n",
       "WHALLEY LAWRENCE G           5.478605             5.907598          6.446565   \n",
       "WHITE JR THOMAS E            6.035615             0.000000          7.141358   \n",
       "YEAGER F SCOTT               5.170118             0.000000          6.553423   \n",
       "\n",
       "                             bonus_over_salary  stock_value_over_salary  \n",
       "ALLEN PHILLIP K                       1.335917                 0.980639  \n",
       "BANNANTINE JAMES M                    0.000000                 4.041141  \n",
       "BAXTER JOHN C                         0.739783                 1.610365  \n",
       "BAY FRANKLIN R                        0.426341                 0.101375  \n",
       "BAZELIDES PHILIP J                    0.000000                 1.317920  \n",
       "BECK SALLY W                          0.604872                 0.188870  \n",
       "BELDEN TIMOTHY N                      1.407099                 0.791707  \n",
       "BELFER ROBERT                              NaN                      inf  \n",
       "BERBERIAN DAVID                       0.000000                 1.097379  \n",
       "BERGSIEKER RICHARD P                  0.367419                 0.653993  \n",
       "BHATNAGAR SANJAY                           NaN                      NaN  \n",
       "BIBI PHILIPPE A                       0.754432                 0.983675  \n",
       "BLACHMAN JEREMY M                     0.645411                 0.684823  \n",
       "BOWEN JR RAYMOND M                    0.766832                 0.279830  \n",
       "BROWN MICHAEL                              NaN                      NaN  \n",
       "BUCHANAN HAROLD G                     0.479430                 0.706758  \n",
       "BUTTS ROBERT H                        0.587474                 0.414458  \n",
       "BUY RICHARD B                         0.570866                 1.057687  \n",
       "CALGER CHRISTOPHER F                  0.792688                 0.183184  \n",
       "CARTER REBECCA C                      0.331604                 0.000000  \n",
       "CAUSEY RICHARD A                      0.532569                 0.846728  \n",
       "COLWELL WESLEY                        0.712552                 0.534013  \n",
       "CORDES WILLIAM R                           NaN                      inf  \n",
       "COX DAVID                             0.549670                 0.411115  \n",
       "CUMBERLAND MICHAEL S                  0.440550                 0.327280  \n",
       "DEFFNER JOSEPH M                      0.592278                 0.248565  \n",
       "DELAINEY DAVID W                      0.964519                 1.037333  \n",
       "DERRICK JR. JAMES V                   0.419093                 1.277320  \n",
       "DETMERING TIMOTHY J                   0.479863                 1.026679  \n",
       "DIETRICH JANET R                      0.531356                 0.927235  \n",
       "...                                        ...                      ...  \n",
       "PAI LOU L                             0.682917                 1.963552  \n",
       "PICKERING MARK R                      0.163754                 0.018685  \n",
       "PIPER GREGORY F                       0.481374                 0.737703  \n",
       "PIRO JIM                                   NaN                      inf  \n",
       "POWERS WILLIAM                             NaN                      NaN  \n",
       "PRENTICE JAMES                             NaN                      inf  \n",
       "REDMOND BRIAN L                       0.000000                 1.916338  \n",
       "REYNOLDS LAWRENCE                     0.363408                 1.750208  \n",
       "RICE KENNETH D                        0.712681                 1.737125  \n",
       "RIEKER PAULA H                        0.580808                 0.939527  \n",
       "SHANKMAN JEFFREY A                    0.879473                 0.892842  \n",
       "SHAPIRO RICHARD S                     0.533476                 0.669141  \n",
       "SHARP VICTORIA T                      0.533763                 0.475862  \n",
       "SHELBY REX                            0.288717                 1.106225  \n",
       "SHERRICK JEFFREY B                         NaN                      inf  \n",
       "SHERRIFF JOHN R                       0.653048                 0.918942  \n",
       "SKILLING JEFFREY K                    0.780989                 1.388833  \n",
       "STABLER FRANK                         0.489630                 0.496467  \n",
       "SULLIVAN-SHAKLOVITZ COLLEEN           0.207992                 0.971715  \n",
       "SUNDE MARTIN                          0.570379                 0.569889  \n",
       "TAYLOR MITCHELL S                     0.513527                 1.179576  \n",
       "THORN TERENCE H                       0.000000                 1.355886  \n",
       "TILNEY ELIZABETH A                    0.344965                 0.757582  \n",
       "UMANOFF ADAM S                        0.572073                 0.000000  \n",
       "WALLS JR ROBERT H                     0.528961                 1.243524  \n",
       "WASAFF GEORGE                         0.352186                 0.949851  \n",
       "WESTFAHL RICHARD K                    0.000000                 0.847492  \n",
       "WHALLEY LAWRENCE G                    0.837472                 1.110972  \n",
       "WHITE JR THOMAS E                     0.383300                 1.687454  \n",
       "YEAGER F SCOTT                        0.000000                 1.880977  \n",
       "\n",
       "[116 rows x 11 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_df.apply(abs).apply(add_one).apply(np.log10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>expenses</th>\n",
       "      <th>other</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>bonus_over_salary</th>\n",
       "      <th>stock_value_over_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALLEN PHILLIP K</th>\n",
       "      <td>5.305257</td>\n",
       "      <td>6.651709</td>\n",
       "      <td>6.620657</td>\n",
       "      <td>6.488700</td>\n",
       "      <td>6.237931</td>\n",
       "      <td>4.142045</td>\n",
       "      <td>2.184691</td>\n",
       "      <td>5.484024</td>\n",
       "      <td>5.100467</td>\n",
       "      <td>1.335917</td>\n",
       "      <td>0.980639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANNANTINE JAMES M</th>\n",
       "      <td>2.679428</td>\n",
       "      <td>5.961989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.707996</td>\n",
       "      <td>6.719620</td>\n",
       "      <td>4.750524</td>\n",
       "      <td>5.936777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.244908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.041141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>5.426679</td>\n",
       "      <td>6.750843</td>\n",
       "      <td>6.079182</td>\n",
       "      <td>6.141781</td>\n",
       "      <td>7.026258</td>\n",
       "      <td>4.049257</td>\n",
       "      <td>6.424931</td>\n",
       "      <td>6.200319</td>\n",
       "      <td>6.595795</td>\n",
       "      <td>0.739783</td>\n",
       "      <td>1.610365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAY FRANKLIN R</th>\n",
       "      <td>5.379617</td>\n",
       "      <td>5.917871</td>\n",
       "      <td>5.602061</td>\n",
       "      <td>5.304581</td>\n",
       "      <td>4.799444</td>\n",
       "      <td>5.111071</td>\n",
       "      <td>1.845098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163749</td>\n",
       "      <td>0.426341</td>\n",
       "      <td>0.101375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAZELIDES PHILIP J</th>\n",
       "      <td>4.907513</td>\n",
       "      <td>5.934568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.204023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.942008</td>\n",
       "      <td>4.971976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.317920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BECK SALLY W</th>\n",
       "      <td>5.364234</td>\n",
       "      <td>5.986355</td>\n",
       "      <td>5.845099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.100467</td>\n",
       "      <td>4.570228</td>\n",
       "      <td>2.753583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.100467</td>\n",
       "      <td>0.604872</td>\n",
       "      <td>0.188870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BELDEN TIMOTHY N</th>\n",
       "      <td>5.330414</td>\n",
       "      <td>6.740491</td>\n",
       "      <td>6.720159</td>\n",
       "      <td>6.368182</td>\n",
       "      <td>6.045599</td>\n",
       "      <td>4.239450</td>\n",
       "      <td>5.323662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.197474</td>\n",
       "      <td>1.407099</td>\n",
       "      <td>0.791707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BELFER ROBERT</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.010728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.644379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERBERIAN DAVID</th>\n",
       "      <td>5.335624</td>\n",
       "      <td>5.358839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.396830</td>\n",
       "      <td>4.075291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.939130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.097379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERGSIEKER RICHARD P</th>\n",
       "      <td>5.273980</td>\n",
       "      <td>5.791586</td>\n",
       "      <td>5.397942</td>\n",
       "      <td>5.686470</td>\n",
       "      <td>5.819050</td>\n",
       "      <td>4.772146</td>\n",
       "      <td>5.630750</td>\n",
       "      <td>5.255878</td>\n",
       "      <td>5.819050</td>\n",
       "      <td>0.367419</td>\n",
       "      <td>0.653993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BHATNAGAR SANJAY</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.189105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.139454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.415723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIBI PHILIPPE A</th>\n",
       "      <td>5.329654</td>\n",
       "      <td>6.311244</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.265718</td>\n",
       "      <td>4.586137</td>\n",
       "      <td>5.629092</td>\n",
       "      <td>5.567875</td>\n",
       "      <td>5.577587</td>\n",
       "      <td>0.754432</td>\n",
       "      <td>0.983675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLACHMAN JEREMY M</th>\n",
       "      <td>5.395409</td>\n",
       "      <td>6.304240</td>\n",
       "      <td>5.929419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.979710</td>\n",
       "      <td>4.925359</td>\n",
       "      <td>2.436163</td>\n",
       "      <td>5.920024</td>\n",
       "      <td>5.276558</td>\n",
       "      <td>0.645411</td>\n",
       "      <td>0.684823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOWEN JR RAYMOND M</th>\n",
       "      <td>5.444984</td>\n",
       "      <td>6.426445</td>\n",
       "      <td>6.130334</td>\n",
       "      <td>2.921166</td>\n",
       "      <td>5.401497</td>\n",
       "      <td>4.818938</td>\n",
       "      <td>3.210051</td>\n",
       "      <td>5.988690</td>\n",
       "      <td>5.401497</td>\n",
       "      <td>0.766832</td>\n",
       "      <td>0.279830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BROWN MICHAEL</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.692750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.692750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUCHANAN HAROLD G</th>\n",
       "      <td>5.394483</td>\n",
       "      <td>6.023103</td>\n",
       "      <td>5.698971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.006255</td>\n",
       "      <td>2.778874</td>\n",
       "      <td>3.084934</td>\n",
       "      <td>5.484024</td>\n",
       "      <td>5.276558</td>\n",
       "      <td>0.479430</td>\n",
       "      <td>0.706758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUTTS ROBERT H</th>\n",
       "      <td>5.417500</td>\n",
       "      <td>6.104345</td>\n",
       "      <td>5.875062</td>\n",
       "      <td>4.875067</td>\n",
       "      <td>5.620781</td>\n",
       "      <td>3.973636</td>\n",
       "      <td>5.177989</td>\n",
       "      <td>5.243041</td>\n",
       "      <td>5.620781</td>\n",
       "      <td>0.587474</td>\n",
       "      <td>0.414458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUY RICHARD B</th>\n",
       "      <td>5.519233</td>\n",
       "      <td>6.372121</td>\n",
       "      <td>5.954243</td>\n",
       "      <td>5.841899</td>\n",
       "      <td>6.537123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.602682</td>\n",
       "      <td>5.886413</td>\n",
       "      <td>5.955042</td>\n",
       "      <td>0.570866</td>\n",
       "      <td>1.057687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CALGER CHRISTOPHER F</th>\n",
       "      <td>5.380555</td>\n",
       "      <td>6.214658</td>\n",
       "      <td>6.096910</td>\n",
       "      <td>5.419131</td>\n",
       "      <td>5.100467</td>\n",
       "      <td>4.554113</td>\n",
       "      <td>2.687529</td>\n",
       "      <td>5.574384</td>\n",
       "      <td>5.100467</td>\n",
       "      <td>0.792688</td>\n",
       "      <td>0.183184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARTER REBECCA C</th>\n",
       "      <td>5.417986</td>\n",
       "      <td>5.679026</td>\n",
       "      <td>5.477123</td>\n",
       "      <td>5.203558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.733197</td>\n",
       "      <td>4.875067</td>\n",
       "      <td>5.487565</td>\n",
       "      <td>0.331604</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAUSEY RICHARD A</th>\n",
       "      <td>5.618247</td>\n",
       "      <td>6.271553</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.371070</td>\n",
       "      <td>6.398298</td>\n",
       "      <td>4.486785</td>\n",
       "      <td>5.488404</td>\n",
       "      <td>5.544069</td>\n",
       "      <td>6.398298</td>\n",
       "      <td>0.532569</td>\n",
       "      <td>0.846728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLWELL WESLEY</th>\n",
       "      <td>5.460211</td>\n",
       "      <td>6.173287</td>\n",
       "      <td>6.079182</td>\n",
       "      <td>5.158552</td>\n",
       "      <td>5.844007</td>\n",
       "      <td>4.217879</td>\n",
       "      <td>5.007496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.844007</td>\n",
       "      <td>0.712552</td>\n",
       "      <td>0.534013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORDES WILLIAM R</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.016275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.586965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COX DAVID</th>\n",
       "      <td>5.497329</td>\n",
       "      <td>6.041943</td>\n",
       "      <td>5.903091</td>\n",
       "      <td>4.615434</td>\n",
       "      <td>5.695161</td>\n",
       "      <td>4.445012</td>\n",
       "      <td>2.694605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.577587</td>\n",
       "      <td>0.549670</td>\n",
       "      <td>0.411115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CUMBERLAND MICHAEL S</th>\n",
       "      <td>5.266937</td>\n",
       "      <td>5.907388</td>\n",
       "      <td>5.511885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.317940</td>\n",
       "      <td>4.349180</td>\n",
       "      <td>2.853698</td>\n",
       "      <td>5.439334</td>\n",
       "      <td>5.317940</td>\n",
       "      <td>0.440550</td>\n",
       "      <td>0.327280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEFFNER JOSEPH M</th>\n",
       "      <td>5.314124</td>\n",
       "      <td>6.082301</td>\n",
       "      <td>5.778152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.201976</td>\n",
       "      <td>4.619375</td>\n",
       "      <td>4.407459</td>\n",
       "      <td>5.525498</td>\n",
       "      <td>5.151780</td>\n",
       "      <td>0.592278</td>\n",
       "      <td>0.248565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DELAINEY DAVID W</th>\n",
       "      <td>5.562488</td>\n",
       "      <td>6.676509</td>\n",
       "      <td>6.477121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.558020</td>\n",
       "      <td>4.935381</td>\n",
       "      <td>3.220631</td>\n",
       "      <td>6.112264</td>\n",
       "      <td>6.121609</td>\n",
       "      <td>0.964519</td>\n",
       "      <td>1.037333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DERRICK JR. JAMES V</th>\n",
       "      <td>5.692297</td>\n",
       "      <td>5.741137</td>\n",
       "      <td>5.903091</td>\n",
       "      <td>6.108565</td>\n",
       "      <td>6.946055</td>\n",
       "      <td>4.708633</td>\n",
       "      <td>3.874076</td>\n",
       "      <td>5.684846</td>\n",
       "      <td>6.252217</td>\n",
       "      <td>0.419093</td>\n",
       "      <td>1.277320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DETMERING TIMOTHY J</th>\n",
       "      <td>5.323254</td>\n",
       "      <td>6.080837</td>\n",
       "      <td>5.628390</td>\n",
       "      <td>5.889437</td>\n",
       "      <td>6.307039</td>\n",
       "      <td>4.718136</td>\n",
       "      <td>3.043755</td>\n",
       "      <td>5.618736</td>\n",
       "      <td>5.498406</td>\n",
       "      <td>0.479863</td>\n",
       "      <td>1.026679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIETRICH JANET R</th>\n",
       "      <td>5.398115</td>\n",
       "      <td>6.149362</td>\n",
       "      <td>5.778152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.270699</td>\n",
       "      <td>3.541080</td>\n",
       "      <td>2.675778</td>\n",
       "      <td>5.745400</td>\n",
       "      <td>5.498406</td>\n",
       "      <td>0.531356</td>\n",
       "      <td>0.927235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAI LOU L</th>\n",
       "      <td>5.418102</td>\n",
       "      <td>6.494625</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.376904</td>\n",
       "      <td>4.505801</td>\n",
       "      <td>6.262322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.927050</td>\n",
       "      <td>0.682917</td>\n",
       "      <td>1.963552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PICKERING MARK R</th>\n",
       "      <td>5.816266</td>\n",
       "      <td>6.141980</td>\n",
       "      <td>5.477123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.459377</td>\n",
       "      <td>4.500429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163754</td>\n",
       "      <td>0.018685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIPER GREGORY F</th>\n",
       "      <td>5.294669</td>\n",
       "      <td>6.239957</td>\n",
       "      <td>5.602061</td>\n",
       "      <td>4.522887</td>\n",
       "      <td>5.944626</td>\n",
       "      <td>4.634054</td>\n",
       "      <td>2.891537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.612312</td>\n",
       "      <td>0.481374</td>\n",
       "      <td>0.737703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIRO JIM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.674907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.674907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POWERS WILLIAM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.243063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRENTICE JAMES</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.751548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.039430</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.319751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REDMOND BRIAN L</th>\n",
       "      <td>4.986059</td>\n",
       "      <td>5.047392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.897095</td>\n",
       "      <td>4.167022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.581251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.916338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REYNOLDS LAWRENCE</th>\n",
       "      <td>4.883093</td>\n",
       "      <td>5.596021</td>\n",
       "      <td>5.000004</td>\n",
       "      <td>5.301032</td>\n",
       "      <td>6.625507</td>\n",
       "      <td>3.924796</td>\n",
       "      <td>5.305465</td>\n",
       "      <td>5.193823</td>\n",
       "      <td>5.304241</td>\n",
       "      <td>0.363408</td>\n",
       "      <td>1.750208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RICE KENNETH D</th>\n",
       "      <td>5.623907</td>\n",
       "      <td>5.703335</td>\n",
       "      <td>6.243038</td>\n",
       "      <td>6.544612</td>\n",
       "      <td>7.353003</td>\n",
       "      <td>4.671645</td>\n",
       "      <td>5.242641</td>\n",
       "      <td>6.208713</td>\n",
       "      <td>6.439074</td>\n",
       "      <td>0.712681</td>\n",
       "      <td>1.737125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RIEKER PAULA H</th>\n",
       "      <td>5.396552</td>\n",
       "      <td>6.041038</td>\n",
       "      <td>5.845099</td>\n",
       "      <td>5.000004</td>\n",
       "      <td>6.283050</td>\n",
       "      <td>4.522079</td>\n",
       "      <td>3.290257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.452783</td>\n",
       "      <td>0.580808</td>\n",
       "      <td>0.939527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHANKMAN JEFFREY A</th>\n",
       "      <td>5.483032</td>\n",
       "      <td>6.482688</td>\n",
       "      <td>6.301030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.316397</td>\n",
       "      <td>5.252805</td>\n",
       "      <td>3.076276</td>\n",
       "      <td>5.743841</td>\n",
       "      <td>5.799436</td>\n",
       "      <td>0.879473</td>\n",
       "      <td>0.892842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAPIRO RICHARD S</th>\n",
       "      <td>5.429877</td>\n",
       "      <td>6.024300</td>\n",
       "      <td>5.812914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.994318</td>\n",
       "      <td>5.139148</td>\n",
       "      <td>2.848805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.578828</td>\n",
       "      <td>0.533476</td>\n",
       "      <td>0.669141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHARP VICTORIA T</th>\n",
       "      <td>5.394709</td>\n",
       "      <td>6.197697</td>\n",
       "      <td>5.778152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.693847</td>\n",
       "      <td>5.065722</td>\n",
       "      <td>3.380573</td>\n",
       "      <td>5.625476</td>\n",
       "      <td>5.328510</td>\n",
       "      <td>0.533763</td>\n",
       "      <td>0.475862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHELBY REX</th>\n",
       "      <td>5.326018</td>\n",
       "      <td>6.301873</td>\n",
       "      <td>5.301032</td>\n",
       "      <td>3.619928</td>\n",
       "      <td>6.396830</td>\n",
       "      <td>4.359551</td>\n",
       "      <td>6.196818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.939130</td>\n",
       "      <td>0.288717</td>\n",
       "      <td>1.106225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHERRICK JEFFREY B</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.263037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.608526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHERRIFF JOHN R</th>\n",
       "      <td>5.632236</td>\n",
       "      <td>6.637028</td>\n",
       "      <td>6.176092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.495403</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.267685</td>\n",
       "      <td>5.743841</td>\n",
       "      <td>6.111741</td>\n",
       "      <td>0.653048</td>\n",
       "      <td>0.918942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SKILLING JEFFREY K</th>\n",
       "      <td>6.045815</td>\n",
       "      <td>6.938656</td>\n",
       "      <td>6.748188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.416535</td>\n",
       "      <td>4.467416</td>\n",
       "      <td>4.344844</td>\n",
       "      <td>6.283301</td>\n",
       "      <td>6.835289</td>\n",
       "      <td>0.780989</td>\n",
       "      <td>1.388833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABLER FRANK</th>\n",
       "      <td>5.379311</td>\n",
       "      <td>6.046139</td>\n",
       "      <td>5.698971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.709045</td>\n",
       "      <td>4.217879</td>\n",
       "      <td>5.551538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.709045</td>\n",
       "      <td>0.489630</td>\n",
       "      <td>0.496467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SULLIVAN-SHAKLOVITZ COLLEEN</th>\n",
       "      <td>5.211601</td>\n",
       "      <td>5.999721</td>\n",
       "      <td>5.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.134297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.212188</td>\n",
       "      <td>5.743841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207992</td>\n",
       "      <td>0.971715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUNDE MARTIN</th>\n",
       "      <td>5.410755</td>\n",
       "      <td>6.188945</td>\n",
       "      <td>5.845099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.844428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.045804</td>\n",
       "      <td>5.678019</td>\n",
       "      <td>5.844428</td>\n",
       "      <td>0.570379</td>\n",
       "      <td>0.569889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAYLOR MITCHELL S</th>\n",
       "      <td>5.423598</td>\n",
       "      <td>6.038487</td>\n",
       "      <td>5.778152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.573458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.751124</td>\n",
       "      <td>0.513527</td>\n",
       "      <td>1.179576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THORN TERENCE H</th>\n",
       "      <td>5.346537</td>\n",
       "      <td>5.959735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.682848</td>\n",
       "      <td>4.664134</td>\n",
       "      <td>5.630051</td>\n",
       "      <td>5.301032</td>\n",
       "      <td>5.562675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.355886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TILNEY ELIZABETH A</th>\n",
       "      <td>5.393293</td>\n",
       "      <td>5.601402</td>\n",
       "      <td>5.477123</td>\n",
       "      <td>5.759669</td>\n",
       "      <td>6.067459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.182004</td>\n",
       "      <td>5.439334</td>\n",
       "      <td>5.761020</td>\n",
       "      <td>0.344965</td>\n",
       "      <td>0.757582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMANOFF ADAM S</th>\n",
       "      <td>5.460281</td>\n",
       "      <td>6.053256</td>\n",
       "      <td>5.896940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.725283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.572073</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALLS JR ROBERT H</th>\n",
       "      <td>5.552780</td>\n",
       "      <td>6.254978</td>\n",
       "      <td>5.929419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.770778</td>\n",
       "      <td>4.707033</td>\n",
       "      <td>0.477121</td>\n",
       "      <td>5.732998</td>\n",
       "      <td>6.191019</td>\n",
       "      <td>0.528961</td>\n",
       "      <td>1.243524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WASAFF GEORGE</th>\n",
       "      <td>5.414968</td>\n",
       "      <td>6.014687</td>\n",
       "      <td>5.511885</td>\n",
       "      <td>5.765911</td>\n",
       "      <td>6.313114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.154120</td>\n",
       "      <td>5.301032</td>\n",
       "      <td>5.589020</td>\n",
       "      <td>0.352186</td>\n",
       "      <td>0.949851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WESTFAHL RICHARD K</th>\n",
       "      <td>4.804446</td>\n",
       "      <td>5.882032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.033464</td>\n",
       "      <td>5.585383</td>\n",
       "      <td>4.714925</td>\n",
       "      <td>5.603286</td>\n",
       "      <td>5.408566</td>\n",
       "      <td>5.585383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.847492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHALLEY LAWRENCE G</th>\n",
       "      <td>5.707881</td>\n",
       "      <td>6.670021</td>\n",
       "      <td>6.477121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.783842</td>\n",
       "      <td>4.762221</td>\n",
       "      <td>5.478605</td>\n",
       "      <td>5.907598</td>\n",
       "      <td>6.446565</td>\n",
       "      <td>0.837472</td>\n",
       "      <td>1.110972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHITE JR THOMAS E</th>\n",
       "      <td>5.501804</td>\n",
       "      <td>6.286537</td>\n",
       "      <td>5.653213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.180244</td>\n",
       "      <td>4.910379</td>\n",
       "      <td>6.035615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.141358</td>\n",
       "      <td>0.383300</td>\n",
       "      <td>1.687454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAGER F SCOTT</th>\n",
       "      <td>5.199766</td>\n",
       "      <td>5.556665</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.074990</td>\n",
       "      <td>4.731975</td>\n",
       "      <td>5.170118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.553423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.880977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               salary  total_payments     bonus  \\\n",
       "ALLEN PHILLIP K              5.305257        6.651709  6.620657   \n",
       "BANNANTINE JAMES M           2.679428        5.961989  0.000000   \n",
       "BAXTER JOHN C                5.426679        6.750843  6.079182   \n",
       "BAY FRANKLIN R               5.379617        5.917871  5.602061   \n",
       "BAZELIDES PHILIP J           4.907513        5.934568  0.000000   \n",
       "BECK SALLY W                 5.364234        5.986355  5.845099   \n",
       "BELDEN TIMOTHY N             5.330414        6.740491  6.720159   \n",
       "BELFER ROBERT                0.000000        5.010728  0.000000   \n",
       "BERBERIAN DAVID              5.335624        5.358839  0.000000   \n",
       "BERGSIEKER RICHARD P         5.273980        5.791586  5.397942   \n",
       "BHATNAGAR SANJAY             0.000000        7.189105  0.000000   \n",
       "BIBI PHILIPPE A              5.329654        6.311244  6.000000   \n",
       "BLACHMAN JEREMY M            5.395409        6.304240  5.929419   \n",
       "BOWEN JR RAYMOND M           5.444984        6.426445  6.130334   \n",
       "BROWN MICHAEL                0.000000        4.692750  0.000000   \n",
       "BUCHANAN HAROLD G            5.394483        6.023103  5.698971   \n",
       "BUTTS ROBERT H               5.417500        6.104345  5.875062   \n",
       "BUY RICHARD B                5.519233        6.372121  5.954243   \n",
       "CALGER CHRISTOPHER F         5.380555        6.214658  6.096910   \n",
       "CARTER REBECCA C             5.417986        5.679026  5.477123   \n",
       "CAUSEY RICHARD A             5.618247        6.271553  6.000000   \n",
       "COLWELL WESLEY               5.460211        6.173287  6.079182   \n",
       "CORDES WILLIAM R             0.000000        0.000000  0.000000   \n",
       "COX DAVID                    5.497329        6.041943  5.903091   \n",
       "CUMBERLAND MICHAEL S         5.266937        5.907388  5.511885   \n",
       "DEFFNER JOSEPH M             5.314124        6.082301  5.778152   \n",
       "DELAINEY DAVID W             5.562488        6.676509  6.477121   \n",
       "DERRICK JR. JAMES V          5.692297        5.741137  5.903091   \n",
       "DETMERING TIMOTHY J          5.323254        6.080837  5.628390   \n",
       "DIETRICH JANET R             5.398115        6.149362  5.778152   \n",
       "...                               ...             ...       ...   \n",
       "PAI LOU L                    5.418102        6.494625  6.000000   \n",
       "PICKERING MARK R             5.816266        6.141980  5.477123   \n",
       "PIPER GREGORY F              5.294669        6.239957  5.602061   \n",
       "PIRO JIM                     0.000000        0.000000  0.000000   \n",
       "POWERS WILLIAM               0.000000        0.000000  0.000000   \n",
       "PRENTICE JAMES               0.000000        5.751548  0.000000   \n",
       "REDMOND BRIAN L              4.986059        5.047392  0.000000   \n",
       "REYNOLDS LAWRENCE            4.883093        5.596021  5.000004   \n",
       "RICE KENNETH D               5.623907        5.703335  6.243038   \n",
       "RIEKER PAULA H               5.396552        6.041038  5.845099   \n",
       "SHANKMAN JEFFREY A           5.483032        6.482688  6.301030   \n",
       "SHAPIRO RICHARD S            5.429877        6.024300  5.812914   \n",
       "SHARP VICTORIA T             5.394709        6.197697  5.778152   \n",
       "SHELBY REX                   5.326018        6.301873  5.301032   \n",
       "SHERRICK JEFFREY B           0.000000        0.000000  0.000000   \n",
       "SHERRIFF JOHN R              5.632236        6.637028  6.176092   \n",
       "SKILLING JEFFREY K           6.045815        6.938656  6.748188   \n",
       "STABLER FRANK                5.379311        6.046139  5.698971   \n",
       "SULLIVAN-SHAKLOVITZ COLLEEN  5.211601        5.999721  5.000004   \n",
       "SUNDE MARTIN                 5.410755        6.188945  5.845099   \n",
       "TAYLOR MITCHELL S            5.423598        6.038487  5.778152   \n",
       "THORN TERENCE H              5.346537        5.959735  0.000000   \n",
       "TILNEY ELIZABETH A           5.393293        5.601402  5.477123   \n",
       "UMANOFF ADAM S               5.460281        6.053256  5.896940   \n",
       "WALLS JR ROBERT H            5.552780        6.254978  5.929419   \n",
       "WASAFF GEORGE                5.414968        6.014687  5.511885   \n",
       "WESTFAHL RICHARD K           4.804446        5.882032  0.000000   \n",
       "WHALLEY LAWRENCE G           5.707881        6.670021  6.477121   \n",
       "WHITE JR THOMAS E            5.501804        6.286537  5.653213   \n",
       "YEAGER F SCOTT               5.199766        5.556665  0.000000   \n",
       "\n",
       "                             deferred_income  total_stock_value  expenses  \\\n",
       "ALLEN PHILLIP K                     6.488700           6.237931  4.142045   \n",
       "BANNANTINE JAMES M                  3.707996           6.719620  4.750524   \n",
       "BAXTER JOHN C                       6.141781           7.026258  4.049257   \n",
       "BAY FRANKLIN R                      5.304581           4.799444  5.111071   \n",
       "BAZELIDES PHILIP J                  0.000000           6.204023  0.000000   \n",
       "BECK SALLY W                        0.000000           5.100467  4.570228   \n",
       "BELDEN TIMOTHY N                    6.368182           6.045599  4.239450   \n",
       "BELFER ROBERT                       0.000000           4.644379  0.000000   \n",
       "BERBERIAN DAVID                     0.000000           6.396830  4.075291   \n",
       "BERGSIEKER RICHARD P                5.686470           5.819050  4.772146   \n",
       "BHATNAGAR SANJAY                    0.000000           0.000000  0.000000   \n",
       "BIBI PHILIPPE A                     0.000000           6.265718  4.586137   \n",
       "BLACHMAN JEREMY M                   0.000000           5.979710  4.925359   \n",
       "BOWEN JR RAYMOND M                  2.921166           5.401497  4.818938   \n",
       "BROWN MICHAEL                       0.000000           0.000000  4.692750   \n",
       "BUCHANAN HAROLD G                   0.000000           6.006255  2.778874   \n",
       "BUTTS ROBERT H                      4.875067           5.620781  3.973636   \n",
       "BUY RICHARD B                       5.841899           6.537123  0.000000   \n",
       "CALGER CHRISTOPHER F                5.419131           5.100467  4.554113   \n",
       "CARTER REBECCA C                    5.203558           0.000000  0.000000   \n",
       "CAUSEY RICHARD A                    5.371070           6.398298  4.486785   \n",
       "COLWELL WESLEY                      5.158552           5.844007  4.217879   \n",
       "CORDES WILLIAM R                    0.000000           6.016275  0.000000   \n",
       "COX DAVID                           4.615434           5.695161  4.445012   \n",
       "CUMBERLAND MICHAEL S                0.000000           5.317940  4.349180   \n",
       "DEFFNER JOSEPH M                    0.000000           5.201976  4.619375   \n",
       "DELAINEY DAVID W                    0.000000           6.558020  4.935381   \n",
       "DERRICK JR. JAMES V                 6.108565           6.946055  4.708633   \n",
       "DETMERING TIMOTHY J                 5.889437           6.307039  4.718136   \n",
       "DIETRICH JANET R                    0.000000           6.270699  3.541080   \n",
       "...                                      ...                ...       ...   \n",
       "PAI LOU L                           0.000000           7.376904  4.505801   \n",
       "PICKERING MARK R                    0.000000           4.459377  4.500429   \n",
       "PIPER GREGORY F                     4.522887           5.944626  4.634054   \n",
       "PIRO JIM                            0.000000           4.674907  0.000000   \n",
       "POWERS WILLIAM                      4.243063           0.000000  0.000000   \n",
       "PRENTICE JAMES                      0.000000           6.039430  0.000000   \n",
       "REDMOND BRIAN L                     0.000000           6.897095  4.167022   \n",
       "REYNOLDS LAWRENCE                   5.301032           6.625507  3.924796   \n",
       "RICE KENNETH D                      6.544612           7.353003  4.671645   \n",
       "RIEKER PAULA H                      5.000004           6.283050  4.522079   \n",
       "SHANKMAN JEFFREY A                  0.000000           6.316397  5.252805   \n",
       "SHAPIRO RICHARD S                   0.000000           5.994318  5.139148   \n",
       "SHARP VICTORIA T                    0.000000           5.693847  5.065722   \n",
       "SHELBY REX                          3.619928           6.396830  4.359551   \n",
       "SHERRICK JEFFREY B                  0.000000           6.263037  0.000000   \n",
       "SHERRIFF JOHN R                     0.000000           6.495403  0.000000   \n",
       "SKILLING JEFFREY K                  0.000000           7.416535  4.467416   \n",
       "STABLER FRANK                       0.000000           5.709045  4.217879   \n",
       "SULLIVAN-SHAKLOVITZ COLLEEN         0.000000           6.134297  0.000000   \n",
       "SUNDE MARTIN                        0.000000           5.844428  0.000000   \n",
       "TAYLOR MITCHELL S                   0.000000           6.573458  0.000000   \n",
       "THORN TERENCE H                     0.000000           6.682848  4.664134   \n",
       "TILNEY ELIZABETH A                  5.759669           6.067459  0.000000   \n",
       "UMANOFF ADAM S                      0.000000           0.000000  4.725283   \n",
       "WALLS JR ROBERT H                   0.000000           6.770778  4.707033   \n",
       "WASAFF GEORGE                       5.765911           6.313114  0.000000   \n",
       "WESTFAHL RICHARD K                  4.033464           5.585383  4.714925   \n",
       "WHALLEY LAWRENCE G                  0.000000           6.783842  4.762221   \n",
       "WHITE JR THOMAS E                   0.000000           7.180244  4.910379   \n",
       "YEAGER F SCOTT                      0.000000           7.074990  4.731975   \n",
       "\n",
       "                                other  long_term_incentive  restricted_stock  \\\n",
       "ALLEN PHILLIP K              2.184691             5.484024          5.100467   \n",
       "BANNANTINE JAMES M           5.936777             0.000000          6.244908   \n",
       "BAXTER JOHN C                6.424931             6.200319          6.595795   \n",
       "BAY FRANKLIN R               1.845098             0.000000          5.163749   \n",
       "BAZELIDES PHILIP J           2.942008             4.971976          0.000000   \n",
       "BECK SALLY W                 2.753583             0.000000          5.100467   \n",
       "BELDEN TIMOTHY N             5.323662             0.000000          5.197474   \n",
       "BELFER ROBERT                0.000000             0.000000          0.000000   \n",
       "BERBERIAN DAVID              0.000000             0.000000          5.939130   \n",
       "BERGSIEKER RICHARD P         5.630750             5.255878          5.819050   \n",
       "BHATNAGAR SANJAY             5.139454             0.000000          6.415723   \n",
       "BIBI PHILIPPE A              5.629092             5.567875          5.577587   \n",
       "BLACHMAN JEREMY M            2.436163             5.920024          5.276558   \n",
       "BOWEN JR RAYMOND M           3.210051             5.988690          5.401497   \n",
       "BROWN MICHAEL                0.000000             0.000000          0.000000   \n",
       "BUCHANAN HAROLD G            3.084934             5.484024          5.276558   \n",
       "BUTTS ROBERT H               5.177989             5.243041          5.620781   \n",
       "BUY RICHARD B                5.602682             5.886413          5.955042   \n",
       "CALGER CHRISTOPHER F         2.687529             5.574384          5.100467   \n",
       "CARTER REBECCA C             2.733197             4.875067          5.487565   \n",
       "CAUSEY RICHARD A             5.488404             5.544069          6.398298   \n",
       "COLWELL WESLEY               5.007496             0.000000          5.844007   \n",
       "CORDES WILLIAM R             0.000000             0.000000          5.586965   \n",
       "COX DAVID                    2.694605             0.000000          5.577587   \n",
       "CUMBERLAND MICHAEL S         2.853698             5.439334          5.317940   \n",
       "DEFFNER JOSEPH M             4.407459             5.525498          5.151780   \n",
       "DELAINEY DAVID W             3.220631             6.112264          6.121609   \n",
       "DERRICK JR. JAMES V          3.874076             5.684846          6.252217   \n",
       "DETMERING TIMOTHY J          3.043755             5.618736          5.498406   \n",
       "DIETRICH JANET R             2.675778             5.745400          5.498406   \n",
       "...                               ...                  ...               ...   \n",
       "PAI LOU L                    6.262322             0.000000          6.927050   \n",
       "PICKERING MARK R             0.000000             0.000000          0.000000   \n",
       "PIPER GREGORY F              2.891537             0.000000          5.612312   \n",
       "PIRO JIM                     0.000000             0.000000          4.674907   \n",
       "POWERS WILLIAM               0.000000             0.000000          0.000000   \n",
       "PRENTICE JAMES               0.000000             0.000000          5.319751   \n",
       "REDMOND BRIAN L              0.000000             0.000000          5.581251   \n",
       "REYNOLDS LAWRENCE            5.305465             5.193823          5.304241   \n",
       "RICE KENNETH D               5.242641             6.208713          6.439074   \n",
       "RIEKER PAULA H               3.290257             0.000000          5.452783   \n",
       "SHANKMAN JEFFREY A           3.076276             5.743841          5.799436   \n",
       "SHAPIRO RICHARD S            2.848805             0.000000          5.578828   \n",
       "SHARP VICTORIA T             3.380573             5.625476          5.328510   \n",
       "SHELBY REX                   6.196818             0.000000          5.939130   \n",
       "SHERRICK JEFFREY B           0.000000             0.000000          5.608526   \n",
       "SHERRIFF JOHN R              6.267685             5.743841          6.111741   \n",
       "SKILLING JEFFREY K           4.344844             6.283301          6.835289   \n",
       "STABLER FRANK                5.551538             0.000000          5.709045   \n",
       "SULLIVAN-SHAKLOVITZ COLLEEN  2.212188             5.743841          0.000000   \n",
       "SUNDE MARTIN                 5.045804             5.678019          5.844428   \n",
       "TAYLOR MITCHELL S            0.000000             0.000000          5.751124   \n",
       "THORN TERENCE H              5.630051             5.301032          5.562675   \n",
       "TILNEY ELIZABETH A           5.182004             5.439334          5.761020   \n",
       "UMANOFF ADAM S               0.000000             0.000000          0.000000   \n",
       "WALLS JR ROBERT H            0.477121             5.732998          6.191019   \n",
       "WASAFF GEORGE                3.154120             5.301032          5.589020   \n",
       "WESTFAHL RICHARD K           5.603286             5.408566          5.585383   \n",
       "WHALLEY LAWRENCE G           5.478605             5.907598          6.446565   \n",
       "WHITE JR THOMAS E            6.035615             0.000000          7.141358   \n",
       "YEAGER F SCOTT               5.170118             0.000000          6.553423   \n",
       "\n",
       "                             bonus_over_salary  stock_value_over_salary  \n",
       "ALLEN PHILLIP K                       1.335917                 0.980639  \n",
       "BANNANTINE JAMES M                    0.000000                 4.041141  \n",
       "BAXTER JOHN C                         0.739783                 1.610365  \n",
       "BAY FRANKLIN R                        0.426341                 0.101375  \n",
       "BAZELIDES PHILIP J                    0.000000                 1.317920  \n",
       "BECK SALLY W                          0.604872                 0.188870  \n",
       "BELDEN TIMOTHY N                      1.407099                 0.791707  \n",
       "BELFER ROBERT                              NaN                      inf  \n",
       "BERBERIAN DAVID                       0.000000                 1.097379  \n",
       "BERGSIEKER RICHARD P                  0.367419                 0.653993  \n",
       "BHATNAGAR SANJAY                           NaN                      NaN  \n",
       "BIBI PHILIPPE A                       0.754432                 0.983675  \n",
       "BLACHMAN JEREMY M                     0.645411                 0.684823  \n",
       "BOWEN JR RAYMOND M                    0.766832                 0.279830  \n",
       "BROWN MICHAEL                              NaN                      NaN  \n",
       "BUCHANAN HAROLD G                     0.479430                 0.706758  \n",
       "BUTTS ROBERT H                        0.587474                 0.414458  \n",
       "BUY RICHARD B                         0.570866                 1.057687  \n",
       "CALGER CHRISTOPHER F                  0.792688                 0.183184  \n",
       "CARTER REBECCA C                      0.331604                 0.000000  \n",
       "CAUSEY RICHARD A                      0.532569                 0.846728  \n",
       "COLWELL WESLEY                        0.712552                 0.534013  \n",
       "CORDES WILLIAM R                           NaN                      inf  \n",
       "COX DAVID                             0.549670                 0.411115  \n",
       "CUMBERLAND MICHAEL S                  0.440550                 0.327280  \n",
       "DEFFNER JOSEPH M                      0.592278                 0.248565  \n",
       "DELAINEY DAVID W                      0.964519                 1.037333  \n",
       "DERRICK JR. JAMES V                   0.419093                 1.277320  \n",
       "DETMERING TIMOTHY J                   0.479863                 1.026679  \n",
       "DIETRICH JANET R                      0.531356                 0.927235  \n",
       "...                                        ...                      ...  \n",
       "PAI LOU L                             0.682917                 1.963552  \n",
       "PICKERING MARK R                      0.163754                 0.018685  \n",
       "PIPER GREGORY F                       0.481374                 0.737703  \n",
       "PIRO JIM                                   NaN                      inf  \n",
       "POWERS WILLIAM                             NaN                      NaN  \n",
       "PRENTICE JAMES                             NaN                      inf  \n",
       "REDMOND BRIAN L                       0.000000                 1.916338  \n",
       "REYNOLDS LAWRENCE                     0.363408                 1.750208  \n",
       "RICE KENNETH D                        0.712681                 1.737125  \n",
       "RIEKER PAULA H                        0.580808                 0.939527  \n",
       "SHANKMAN JEFFREY A                    0.879473                 0.892842  \n",
       "SHAPIRO RICHARD S                     0.533476                 0.669141  \n",
       "SHARP VICTORIA T                      0.533763                 0.475862  \n",
       "SHELBY REX                            0.288717                 1.106225  \n",
       "SHERRICK JEFFREY B                         NaN                      inf  \n",
       "SHERRIFF JOHN R                       0.653048                 0.918942  \n",
       "SKILLING JEFFREY K                    0.780989                 1.388833  \n",
       "STABLER FRANK                         0.489630                 0.496467  \n",
       "SULLIVAN-SHAKLOVITZ COLLEEN           0.207992                 0.971715  \n",
       "SUNDE MARTIN                          0.570379                 0.569889  \n",
       "TAYLOR MITCHELL S                     0.513527                 1.179576  \n",
       "THORN TERENCE H                       0.000000                 1.355886  \n",
       "TILNEY ELIZABETH A                    0.344965                 0.757582  \n",
       "UMANOFF ADAM S                        0.572073                 0.000000  \n",
       "WALLS JR ROBERT H                     0.528961                 1.243524  \n",
       "WASAFF GEORGE                         0.352186                 0.949851  \n",
       "WESTFAHL RICHARD K                    0.000000                 0.847492  \n",
       "WHALLEY LAWRENCE G                    0.837472                 1.110972  \n",
       "WHITE JR THOMAS E                     0.383300                 1.687454  \n",
       "YEAGER F SCOTT                        0.000000                 1.880977  \n",
       "\n",
       "[116 rows x 11 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid number of arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-a8d033e49c3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinancial_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: invalid number of arguments"
     ]
    }
   ],
   "source": [
    "financial_df.apply(np.add([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def twoFeatureScatter(dataset, f1Label, f2Label):\n",
    "    features = [f1Label, f2Label]\n",
    "    data = featureFormat(dataset, features)\n",
    "    for point in data:\n",
    "        f1 = point[0]\n",
    "        f2 = point[1]\n",
    "        plt.scatter(f1, f2)\n",
    "\n",
    "    plt.xlabel(f1Label)\n",
    "    plt.ylabel(f2Label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAERCAYAAACU1LsdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAG0dJREFUeJzt3WuUXGWd7/Fv54YQGtJAR9JeGuLIP4LIKK6DOEoMKh5Q\nLuqs0XEALxgVdcbMzDIxuHRQDyANS/EcjzgTuR8FlCPEW8KM0gcvBxy8MAu8PFHgZJQOEtLdSTAB\nElLnxa7eXd3pS1V3de2q+P286a7au+r599Pd9av9PHs/1VYqlZAkCWBW0QVIkpqHoSBJyhkKkqSc\noSBJyhkKkqScoSBJys1pdIMRMQe4DjgC2A0sTyltaHQdkqS9FXGkcBowO6X0F8CngIsLqEGSNIYi\nQmEDMCci2oCDgacKqEGSNIaGDx8BjwNHAr8GDgXeUEANkqQxFHGk8PfA+pRSAMcB10fEvALqkCSN\nUsSRQj+wq/z9YLmG2RM9oFQqldra2ma6Lkna19T8wtnW6AXxImI+cDWwCJgLXJFSunmSh5U2b94+\n47VNV2dnO81eZyvUCNZZb9ZZXy1UZ82h0PAjhZTSH4G3NLpdSdLkvHhNkpQzFCRJOUNBkpQzFCRJ\nOUNBkpQzFCRJOUNBkpQzFCRJOUNBkpQzFCRJOUNBkpQzFCRJOUNBkpQzFCRJOUNBkpQzFCRJOUNB\nkpQr4jOaiYi3A+8ASsD+wHHA4SmlbUXUI0nKFBIKKaXrgOsAIuLzwJcMBEkqXqHDRxHxUuDolNJV\nRdYhScoUPaewGvhEwTVIksraSqVSIQ1HxMHAD1NKx1axezFFSlJra6v1AYXMKZSdBHyv2p03b94+\ng6XUR2dne9PX2Qo1gnXWW6vUOWvW05x33jfYuPEguru30tNzMh0dC4ouay+t0p+dne01P6bIUAjg\nwQLbl9Rk3v/+daxdew7Qxr33loAbWLPmjUWXtZctWwZZvrz5w2sqCguFlNLlRbUtqTk99NCBDI94\ntLFx40FFljOuVgmvqSh6olmSckceuZ3hKcQS3d3NeaZ6q4TXVBQ5fCRpH9PfP8iqVb1THla58srT\nePLJG8qP30ZPz7IZrHbqjjxyO/fcMwCsB+bz6KO/YGDg+H1iCKmws49qVGqVSZ1mr7MVagTrrLdG\n1bl8+a35sAqUOPPM2oZVWqU/Z89+mmOP/QJ9fauZ6s/aCJ2d7TWffeTwkaS6yYZR9s1hlUqHHLKA\nhQuPZl/8WQ0FSdPS3z/I8uW3csop3+PRR38BDJS3NO+cQD10d2+lFeY/auWcgqRpWbWqt2LI6Ey6\nui5h4cKjm3pOoB56ek4Gmn/+o1aGgqRpGT1ktHDh0fzrv766yJIaoqNjQdPNIdSDw0eSpqWWYZTK\noably7/OwMBgXfadyv4am0cKkqallmGUyqGmyS76qmXfqeyvsRkKkqallmGU0UNNDzwwm+XLb82v\na7j66jOB2WPue+eduxkYGBz3WoA/lTOfZprDR5IaZvRQU3//RtauPYd77z2LtWvP5fzz14277+Dg\nM1i5srfq595XzgZqNI8UJDXM6KGmBx88ir6+4Xf32fIRw/veeeflDA4uAR4HTmPjxv9T9XPvK2cD\nNZqhIKlhRg81nXvuTdx3X4mhq4Kf9az+EfsuXbqQtWvfkG+f6N1/I88GcpVUSZrEVNY9amvbDdwI\ntAPbKZV2jdg++t3/6tUvGTEHUdSL8b68SqqhIKkupnL2z6ZNi4Cz8tt9fd8csX30u//KtZWKfDHe\nl1dJdaJZUl2MdfbPZNcOjJ4cPvLIx2tqY+iMpEZrlSW+p8IjBUl10d29tfzufXj8f6yjh0svXZYP\nMy1a9BSnnvpFNm1aRHf3Nq688gyefrr6NgYH+1m27Hp6e89t6DBSqyzxPRWFLJ0dER8BzgDmAl9I\nKV0zyUNcOrtOWqFGsM56a0SdAwODrFzZO+KF8s1v/j733z8LOBDYzpIlu9i27eERS053dV1Cb+85\ndHQsmLTOgYFBTjjhJgYHO4F5wGnAwQ1ftrqFfu81L53d8COFiFgKnJhSenlEzAf+sdE1SKq/sc7+\n6e/fCAwHwIYNH2XPnpdSOQTU1/dCVq7sHeOxg6xYcTt33z0LeIwTTzyQK644vXxGUgfZ+8rMvjSm\nX7Qiho9eB9wfEbeRnXLw4QJqkDQDRp+BdPDBz6u4DuE/2bNnLtAPXAK8DXguMMDGjQfv9VyrVvWy\nfv15DAXKunVX8bOfrWHnzgNpa9tBqXQt2ST1wfvUmH7RigiFw8j+Et4ALAa+ASwpoA5JdTZ6DqGr\n62KyCdk24MvAhQy9yMM/kf3rP0V39zb6+wf54Ae/xYYN+9PdvZUHHphD5REFDPKHPywB/jp/jgUL\nLmfp0mfuU2P6RSsiFLYAv0op7QY2RMQTEXFYSumxiR7U2dnemOqmqRXqbIUawTrrrRF19vV1MPxC\nvpUdO2YzZ86/sHv3NqCTkS/yRwBvo6PjWq6++gzOP38dX/3qWxkKlP33/zjDgVIiez/ZPuI5nv/8\nJdx22+kz/nONpVV+77UqIhR+CPwd8NmI6AIOIAuKCbXIpE7T19kKNYJ11lsj6uzvH+Thh+8DdgEJ\ngMHBjzD8on5B+etW4DvAk0AP8+Zt4ze/+T3r1++k8gV/587jgJuA+cyd+xMOPXQOjzwyl8qg6Ooa\nYPPm7VO6cG46Wun3XquGh0JK6dsR8cqI+Hey3+z7U0qNPwVKUl2tWtU74qwiuI6RRwaHAJ8ubxve\n7w9/uJ5XvepmnnjiIEYeGfwW+AgAxxyzh5tvPp4VK77FXXddDhzKiSfuoafndXnbzXBR276gkOsU\nUkofKaJdSTNn9IVlsJmRL/JbgaOB3aP2K/HEE58sb78ReAp4jGzqEYaueejoWMB1151dVduejTR1\nXrwmadr6+wd59NFfAGcyHAIdZC/yA8DDwCLgV2QvO18hmx/YBvyu/JgFZGckfQOYx+GHP8gTT1wN\nbOGpp+ZP+FkKY104p6kxFCRN2dBY/p137i5fUHY90MGsWXezZ88LyV6ktwIXkc0PfLC8z/AZRPvt\n91GefHL4BX3u3J/wmtcsAg5l3bp3Am2sW1di3rzxh4RcNrt+DAVJU1Y5lp8dHdwEnMExxzzF4sU7\neOCB2dx//9BZR0OLyB1C5VDPUUe9hMWLsxf0o47ayac+tZyOjgWccsr3qHZIqJHLZu/rXBBP0pTt\nPY9wIFBiy5YN9PQs43nPexrYSBYY20d9BSixePEOLr10Gd3d23jooQNZufIOBgYG/SS1gnikIGnK\nRo/lZ6eiPk5f39tYtuwGtmw5pHz/NcDvgYuYO3cBs2d/nLa2xXR0bOKCC84Y44jjBoeECmIoSJqy\nnp6TueeeS+jreyGwAXg32YTxjeXTU28C3svwi/2NdHb+P/r6Pkl2LUKJiy++YcyzhxwSKoahIKkq\nlReILVq0CZjLpk2H8fjju8nOMDoM+DbwemA+I+cRANqYM2cbfX0HkZ2VdBqwIL/gzLOHmoOhIKkq\nIy8Q+wrDZxDtoPJsorlzL6azE/r6TiebPxgA1gPz2b17ADgfOJjsKOKt5aGhbKior6+Drq6BGRsq\navSVz63IUJBUlZFDPO3jfN/GkiXBLbecwMqVN/DAA7P57W8/U744rQ04nSwM/hrYyYIFl9PT89Z8\nqGiml4/wyufJefaRpKqMPBto2zjfZ2cTDb3I33HHGSxZcjxjnaEEm4BD87ONGsErnyfnkYKkqlSe\nDbRo0TZ+/vOLeOSRFwE7getZsOBpli6ds9fQz9hnKG0HFjI4+C7Wrm3cO3bnLiZnKEiqyuizgU45\n5Xs88sjwp58dccRtrFnz6r0eNxQmDz54AFu2bOCQQ7r5/e8fZnBweXmPxr1j9zTXyRkKkmqWrXX0\nS7IR6MeBU1m06BGWL781n8Rdvfp4LrnkZ+XbJW655QQ6OrJVTZcv/zpr1w592lrj3rF7muvkDAVJ\nNRu9THZX1yXAwhGTuNn1C6sZa1LXd+zNy1CQVLPRE7YLFx7Npk2MuG9g4NmMN6nrO/bm5dlHkmo2\n1rpEo+/r6PjdXvuo+XmkIKlm4w//DN93wQVn5ktYOETUOgoLhYj4KdlC6wAPpZTOK6oWSbUZb/hn\n9H1r1nQ3qiTVSSGhEBH7AaSUTi6ifUnS2Io6UjgOmB8RtwOzgY+mlH5cUC1Sy2n0Gj6uGfSno6hQ\n2AFcllK6KiKeD6yLiKNSSnsKqkdqKY1ew8c1g/50FBUKG4DfAqSUfhMRW8g+1fvh8R7Q2dneoNKm\npxXqbIUawTon0tfXQeXpnn19HZPWMZ06p9LeVPl7L1ZRofAu4FjgAxHRRbbM4qaJHjCTKyfWy0yv\n8FgPrVAjWOdkurr6yU73HLp4bGDCOqZbZ63tTZW/9/qaSnAVFQpXAddExA+APcC7HDqSqtfoK4Jr\nac/5h9ZWSCiklHYBZxfRtrQvaPQVwbW05/xDa/OKZkl15WcWtDZDQVJdjbUEhlqHy1xIqitXQG1t\nhoKkunIF1Nbm8JEkKWcoSJJyhoIkKWcoSJJyhoIkKWcoSJJyhoIkKWcoSJJyhoIkKWcoSJJyhoIk\nKWcoSJJyhS2IFxELgZ8Ar0kpbSiqDknSsEKOFCJiDvBFYEcR7UuSxlbU8NHlwJVAX0HtS5LG0PBQ\niIh3AI+mlP6N4c/skyQ1gapCISLmRcSLyt+/LSIui4hFU2zzncBrI6IX+HPg+vL8giSpYG2lUmnS\nnSLiq8CvgW8D/wu4HnhlSumU6TReDob3VjHRPHmRkqTRah6NqfbsoyNTSn8VET3Al1JKl0bEPbU2\nNoaqX+w3b95eh+ZmVmdne9PX2Qo1gnXWm3XWVyvVWatqQ2FORBwGnAW8KSIOBw6oubVRUkonT/c5\nJEn1U+1E82XAj4Fvp5TuB74PfHLGqpIkFaKqI4WU0leAr1Tc9YKU0tMzU5IkqShVhUJEPMSo8f+I\nIKW0eEaqkiQVoto5hVdVfD8XeCOwX92rkSQVqtrho42j7rosIn4C/Lf6lyRJKkq1w0cnVdxsA44B\n9p+RiiRJhal2+OgTFd+XgMeAt9e/HElSkaodPlo204VIkopX7fDRi4ELgEOouGzai88kad9S7fDR\n9cA/A/fjOkSStM+qNhR2pJQ+P6OVSJIKV20o3B4RfwvcDjwxdGdK6T9npCpJUiGqDYVzyl//oeK+\nEuAVzZK0D6n27KMjZ7oQSVLxqj37qBP4PPDq8mPuAM5PKf1hBmuTJDVYtUtn/zNwD9lw0RHA3cBV\nM1STJKkg1c4pLE4pvanidk9EnDPu3pKkllRtKJQi4jkppd8BRMRzgV1TbTQiZgFrgAD2AO9LKf1y\nqs8nSaqPakPhY8BdEfHj8u2XAe+ZRrunA6WU0isiYilwMdlHfUqSClTtnMLtwL8Ay8g+W+EK4DtT\nbTSltJbhUDkCGJjqc0mS6qfaI4X/CbSTrYzaVv76WWDFVBtOKe2JiGvJjhD+cqrPI0mqn2pD4WUp\npRcN3YiIbwH/Md3GU0rviIiFwL9HxAtSSjun+5ySpKmrNhQejojFKaUHy7e7gE1TbTQizgaenVL6\nNNmyGU+TTTiPq7OzfarNNVQr1NkKNYJ11pt11ler1FmrCUMhInrJlrPoBP4jIr4P7AZeSbZi6lR9\nHbgmIu4s1/ChlNKTEz1g8+bt02iuMTo725u+zlaoEayz3qyzvlqpzlpNdqRw4Tj3f6bmliqklHYA\nb5nOc0iS6m/CUEgp3dmoQiRJxav2lFRJ0p8AQ0GSlDMUJEk5Q0GSlDMUJEk5Q0GSlDMUJEk5Q0GS\nlDMUJEk5Q0GSlDMUJEk5Q0GSlDMUJEk5Q0GSlDMUJEk5Q0GSlKv2M5rrJiLmAFcDRwDzgItSSt9s\ndB2SpL0VcaRwNvBYSukk4FTg8wXUIEkaQ8OPFICvAl8rfz8L2FVADZKkMTQ8FFJKOwAiop0sHD7a\n6BokSWNrK5VKDW80Ip4DfB34fErpuioe0vgiJan1tdX8gEaHQkQ8E+gFPpBS6q3yYaXNm7fPYFX1\n0dnZTrPX2Qo1gnXWm3XWVwvVWXMoFDGnsBpYAHwsIj5OdhRwakrpyQJqkSRVKGJOYQWwotHtSpIm\n58VrkqScoSBJyhkKkqScoSBJyhkKkqScoSBJyhkKkqScoSBJyhkKkqScoSBJyhkKkqScoSBJyhkK\nkqScoSBJyhkKkqScoSBJyhkKkqRcYaEQESdERLWf0SxJaoAiPqOZiPgwcA7weBHtS5LGVtSRwm+B\nNxbUtiRpHIWEQkrpVmB3EW1LksbXViqVCmk4IrqBG1NKL69i92KKlKTW1lbrAwqZU6hQdcGbN2+f\nyTrqorOzvenrbIUawTrrzTrrq5XqrFXRp6R6BCBJTaSwI4WU0kagmqEjSVKDFH2kIElqIoaCJCln\nKEiScoaCJClnKEiScoaCJClnKEiScoaCJClnKEiScoaCJClnKEiScoaCJClnKEiScoaCJClnKEiS\ncoaCJClnKEiScg3/5LWIaAO+ABwHPAG8O6X0YKPrkCTtrYgjhbOA/VJKLwdWA58poAZJ0hiK+Izm\nVwDrAVJKP46Il85EI/39g6xa1cvGjQfR3b2Vnp6T6ehYMBNNSTNmsr/joe0PPDCb/v6NHHroUSxe\n/EdWrz6eCy+8m7vvngU8xtKlHfT0/Ndx/wcmaqdy2+GHb6atbTebNi0at54VK27P2z3xxAO54orT\na/rf83+3WEWEwkHA1orbuyNiVkppTz0bWbWql7VrzwHauPfeEnADa9a8sZ5NSDNusr/j4e03Aavp\n62vjvvtK3HPPJfT1rQbagBJr194I9I77PzBRO5XboATcCJw1bj3r15+X77tu3Y3Mmzd+u1P5mTWz\nigiFbUB7xe2qAqGzs32yXUbo6+sg+8MEaKOvr6Pm55iKRrQxXa1QI1gnTP53PLz9wBH7DQ4+e8Rt\naKevb/xaJ2pn9Lbhf9+J6qmu3an8zM2iGWuqhyJC4UfAG4BbIuJlwH3VPGjz5u01NdLV1U/2riZ7\nx9LVNVDzc9Sqs7N9xtuYrlaoEaxzyGR/x8Pbt4/Yb8GC37Njx/Bt2E5X1+5xa52ondHbsraYpJ7q\n2h2ts7O9kP/dWrXS32etigiFW4HXRsSPyrffORON9PScDNxQHpfcRk/PsploRppRk/0dD23P5hQu\nKc8p7OCCC87gwguv4q67ZgFbynMKr5tSO5XbFi16DNjFpk23jVvPU08Nt3viiQfS0/OGuv7Mmllt\npVKp6BqqUWqVVG72OluhRrDOerPO+mqhOtsm32skL16TJOUMBUlSzlCQJOUMBUlSzlCQJOUMBUlS\nzlCQJOUMBUlSzlCQJOUMBUlSzlCQJOUMBUlSzlCQJOUMBUlSzlCQJOUMBUlSrrBQiIg3RsSXi2pf\nkrS3Ij6Ok4i4AjgFuLeI9iVJYyvqSOFHwPkFtS1JGseMHilExLuAvwdKQFv56ztTSl+LiKUz2bYk\nqXYzGgoppauBq2eyDUlS/RQypzAFbZ2d7UXXUJVWqLMVagTrrDfrrK9WqbNWnpIqScq1lUqlomuQ\nJDUJjxQkSTlDQZKUMxQkSTlDQZKUa5pTUiNiDtk1DUcA84CLUkrfrNi+Ang38Gj5rvemlH5TQJ2z\ngDVAAHuA96WUflmx/XTgY8Au4JqU0pcaXWOVdTZFf5ZrWQj8BHhNSmlDxf1N0ZcV9YxXZzP15U+B\nreWbD6WUzqvY1jT9OUmdzdSfHwHOAOYCX0gpXVOxrZn6c6I6a+rPpgkF4GzgsZTSuRHRQbYu0jcr\nth8PnJNS+nkh1Q07HSillF5Rvir7YuAsyIPtM2S17gR+FBFrU0qbm6nOsqboz3KffRHYMcb9zdKX\n49ZZ1ix9uR9ASunkMbY1TX9OVGdZs/TnUuDElNLLI2I+8I8V25qpP8ets6ym/mym4aOvkqUuZHXt\nGrX9eGB1RPygnIqFSCmtBd5TvnkEMFCx+QXAb1JK21JKu4AfAic1tsLMJHVCk/QncDlwJdA36v6m\n6cuy8eqE5unL44D5EXF7RHw3Ik6o2NZM/TlRndA8/fk64P6IuA34BvCtim3N1J8T1Qk19mfThEJK\naUdK6Y8R0Q58DfjoqF1uBN4HLANeERGnNbrGISmlPRFxLfA5oHL574MYPiQG2A4c3MDSRpigTmiC\n/oyIdwCPppT+jWxtrEpN05eT1AlN0JdlO4DLUkqvI1tw8svlYURoov5k4jqhefrzMLIX1L8kq/Mr\nFduaqT8nqhNq7M+mCQWAiHgOcAdwXUrp5lGbP5dS6k8p7Qa+Dby44QVWSCm9AzgK+FJE7F++exvZ\nH8uQdmCwwaWNME6d0Bz9+U7gtRHRC/w5cH153B6aqy8nqhOaoy8BNlAO//KY8RZgUXlbM/XnRHVC\n8/TnFuD2lNLu8hzSExFxWHlbM/XnRHVCjf3ZNHMKEfFM4HbgAyml3lHbDiI7PFpCNn53MnBV46uE\niDgbeHZK6dPAE8DTZBO5AL8C/iwiFpC9GzoJuKzZ6myW/kwp5Svlll9w35tSGpoMa5q+nKjOZunL\nsncBxwIfiIgusheqTeVtTdOfTFBnk/XnD4G/Az5brvMAshdgaK7+HLfOqfRn0yxzUf7gnb8Cfs3w\nMttrgPkppS9FxN8AHyJ7gfteSukTBdV5AHANcDhZqH4aOLCiztcD/1T+Ga5KKX2xSetsiv4cEhF3\nkB3iHk+T9WWlcepsir6MiLlkv/NusjcAq4AjabL+rKLOpujPcq2fJnshbQMuIBuqaar+rKLOmvqz\naUJBklS8pppTkCQVy1CQJOUMBUlSzlCQJOUMBUlSzlCQJOUMBalGEdEbEUWuwyTNGENBkpRrmmUu\npCJFxLPI1uM5gOwq2w8BzwX+AXgGsD/w7pTSDyseM5ts5dRjgGcCCXgT2VXkt5OtX/8ksB/wyZTS\nd8uP2wCclFJ6pCE/nFQDjxSkzHnAN1NK/wVYSbaWzXuA16eUXgxcCnx41GNeDjyZUvoL4PlkgTK0\nAuXzgb9JKb2WbK2ZcwAi4pVkSy4bCGpKHilIme8C/zsiXkK2kuTnyD5U5/SICOBVwO7KB6SUfhAR\nWyLi/cAS4M/I1peCbKnt35W//xpwcUQ8A3g7cO0M/yzSlHmkIAEppf8LHA2sJ1uYcT1wD9kHFN0J\n/HdGfZZC+eMYvww8TvZRsj+o2GdnxXPvAL5Tft6Tgdtm7ieRpsdQkICIuBQ4N6V0A/C3ZEcGT6eU\nLgZ6gVOB2aMe9hrg5pTS9WTzBydV7DP6w3iuAS4CvlP+pC6pKRkKUuZ/AG+OiJ8DXwfeAtwbEQn4\nKdkna3WX9x1aWngN8Lbyh9DfAtxFtgR05T5AfiRSwqEjNTmXzpYaICKOBa5NKR1fdC3SRDxSkGZY\nRKwA1gEfKLoWaTIeKUiSch4pSJJyhoIkKWcoSJJyhoIkKWcoSJJyhoIkKff/AbuB4J4muZPjAAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbbcf0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "twoFeatureScatter(dataset, 'salary', 'bonus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA before SelectKBest in order to reduce infromation loss. Using Gaussian NB in one test PCA before SKB increased the F1 score from 0.26316 to 0.35967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('pca', PCA()),\n",
    "        ('skb', SelectKBest())\n",
    "    ])\n",
    "param = {\n",
    "        'skb__k':randint(1,9),\n",
    "        'pca__n_components':randint(8,19)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = []\n",
    "pipes = []\n",
    "params = []\n",
    "\n",
    "names.append('Gaussian Naive Bayes')\n",
    "pipes.append(('gnb', GaussianNB()))\n",
    "params.append({\n",
    "    })\n",
    "\n",
    "names.append('Support Vector Machine')\n",
    "pipes.append(('svc', SVC()))\n",
    "params.append({\n",
    "        'svc__kernel':('poly', 'rbf', 'sigmoid'), \n",
    "        'svc__C':randint(1,151), \n",
    "        'svc__gamma':randint(1,21)\n",
    "    })\n",
    "\n",
    "names.append('Decision Tree Classifier')\n",
    "pipes.append(('dtc', DecisionTreeClassifier()))\n",
    "params.append({\n",
    "        'dtc__criterion':('gini', 'entropy'), \n",
    "        'dtc__splitter':('best', 'random'),\n",
    "        'dtc__min_samples_split':randint(2,26),\n",
    "        'dtc__max_depth':randint(10,51),\n",
    "        'dtc__max_leaf_nodes':randint(5,31)\n",
    "    })\n",
    "\n",
    "names.append('K Neigbors Classifier')\n",
    "pipes.append(('knc', KNeighborsClassifier()))\n",
    "params.append({\n",
    "        'knc__n_neighbors':randint(1, 31), \n",
    "        'knc__weights':('uniform', 'distance')\n",
    "    })\n",
    "\n",
    "names.append('Random Forest Classifier')\n",
    "pipes.append(('rfc', RandomForestClassifier()))\n",
    "params.append({\n",
    "        'rfc__n_estimators':randint(2,21), \n",
    "        'rfc__criterion':('gini','entropy')\n",
    "    })\n",
    "\n",
    "names.append('AdaBoost Classifier')\n",
    "pipes.append(('abc', AdaBoostClassifier()))\n",
    "params.append({\n",
    "        'abc__n_estimators':randint(2,11), \n",
    "        'abc__learning_rate':randint(1,6)\n",
    "    })\n",
    "\n",
    "pipelines = []\n",
    "parameters = []\n",
    "\n",
    "for i in range(0, len(pipes)):\n",
    "    pipelines.append(Pipeline(steps=[x for x in pipe.steps]))\n",
    "    pipelines[i].steps.append(pipes[i])\n",
    "    parameters.append(param.copy())\n",
    "    parameters[i].update(params[i])\n",
    "    \n",
    "classifiers = []\n",
    "classifiers.extend((names, pipelines, parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hold\n",
    "names.append('K Neigbors Classifier (Ball Tree)')\n",
    "pipes.append(('knc', KNeighborsClassifier()))\n",
    "params.append({\n",
    "        'knc__algorithm':['ball_tree'],\n",
    "        'knc__leaf_size':randint(5,100),\n",
    "        'knc__p':randint(1,5),\n",
    "        'knc__n_neighbors':randint(1,26), \n",
    "        'knc__weights':('uniform', 'distance')\n",
    "    })\n",
    "\n",
    "names.append('K Neigbors Classifier (KD Tree)')\n",
    "pipes.append(('knc', KNeighborsClassifier()))\n",
    "params.append({\n",
    "        'knc__algorithm':['kd_tree'],\n",
    "        'knc__leaf_size':randint(5,100),\n",
    "        'knc__p':randint(1,5),\n",
    "        'knc__n_neighbors':randint(1,26), \n",
    "        'knc__weights':('uniform', 'distance')\n",
    "    })\n",
    "\n",
    "names.append('K Neigbors Classifier (Brute)')\n",
    "pipes.append(('knc', KNeighborsClassifier()))\n",
    "params.append({\n",
    "        'knc__algorithm':['brute'],\n",
    "        'knc__p':randint(1,5),\n",
    "        'knc__n_neighbors':randint(1,26), \n",
    "        'knc__weights':('uniform', 'distance')\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_test_classifier(n_iter, n_splits, folds, clfs, dataset, feature_list):\n",
    "    \n",
    "    cv = StratifiedShuffleSplit(n_splits=n_splits, random_state=42, \n",
    "                                          test_size=0.3)\n",
    "    for i in range(0,len(clfs[0])):\n",
    "        print \"\\n\", clfs[0][i], \"------------------------------------------\"\n",
    "        \n",
    "        start = t0 = time() \n",
    "        warnings.filterwarnings('ignore')\n",
    "        rs = RandomizedSearchCV(clfs[1][i], param_distributions=clfs[2][i],\n",
    "                                n_iter=n_iter, scoring='f1', cv=cv,\n",
    "                                random_state=42)\n",
    "        rs.fit(features_df, labels_df)\n",
    "        print \"\\nSearch/Fit Time:\", round(time()-t0, 3), \"s\\n\"\n",
    "\n",
    "        t0 = time() \n",
    "        test_classifier(rs.best_estimator_, dataset, feature_list, folds=folds)\n",
    "        print \"Test Time:\", round(time()-t0, 3), \"s\"\n",
    "    \n",
    "    print \"\\nTotal Run Time:\", round(time()-start, 3), \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_classifier(target, clfs):\n",
    "    for i in range(0,len(clfs[0])):\n",
    "        if clfs[0][i] == target:\n",
    "            clfs[0].remove(clfs[0][i])\n",
    "            clfs[1].remove(clfs[1][i])\n",
    "            clfs[2].remove(clfs[2][i])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "\tAccuracy: 0.79483\tPrecision: 0.35324\tRecall: 0.27800\tF1: 0.31114\tF2: 0.29037\n",
      "\tTotal predictions: 12000\tTrue positives:  556\tFalse positives: 1018\tFalse negatives: 1444\tTrue negatives: 8982\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(GaussianNB(), dataset, feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "\tAccuracy: 0.66992\tPrecision: 0.30542\tRecall: 0.76950\tF1: 0.43728\tF2: 0.59015\n",
      "\tTotal predictions: 12000\tTrue positives: 1539\tFalse positives: 3500\tFalse negatives:  461\tTrue negatives: 6500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(GaussianNB(), dataset, feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Classifiers, first run through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gaussian Naive Bayes ------------------------------------------\n",
      "\n",
      "Search/Fit Time: 19.223 s\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=12, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=2, score_func=<function f_classif at 0x000000000AB30898>)), ('gnb', GaussianNB(priors=None))])\n",
      "\tAccuracy: 0.79983\tPrecision: 0.34173\tRecall: 0.21700\tF1: 0.26544\tF2: 0.23409\n",
      "\tTotal predictions: 12000\tTrue positives:  434\tFalse positives:  836\tFalse negatives: 1566\tTrue negatives: 9164\n",
      "\n",
      "Test Time: 2.018 s\n",
      "\n",
      "Support Vector Machine ------------------------------------------\n",
      "\n",
      "Search/Fit Time: 33.137 s\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=16, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=7, score_func=<function f_classif at 0x000000000AB30898>)), ('svc', SVC(C=18, cache_...,\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "\tAccuracy: 0.78067\tPrecision: 0.26061\tRecall: 0.17200\tF1: 0.20723\tF2: 0.18455\n",
      "\tTotal predictions: 12000\tTrue positives:  344\tFalse positives:  976\tFalse negatives: 1656\tTrue negatives: 9024\n",
      "\n",
      "Test Time: 2.736 s\n",
      "\n",
      "Decision Tree Classifier ------------------------------------------\n",
      "\n",
      "Search/Fit Time: 23.841 s\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=13, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=6, score_func=<function f_classif at 0x000000000AB30898>)), ('dtc', DecisionTreeClas...    min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='random'))])\n",
      "\tAccuracy: 0.79625\tPrecision: 0.19054\tRecall: 0.06850\tF1: 0.10077\tF2: 0.07856\n",
      "\tTotal predictions: 12000\tTrue positives:  137\tFalse positives:  582\tFalse negatives: 1863\tTrue negatives: 9418\n",
      "\n",
      "Test Time: 1.849 s\n",
      "\n",
      "K Neigbors Classifier ------------------------------------------\n",
      "\n",
      "Search/Fit Time: 26.024 s\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=12, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=7, score_func=<function f_classif at 0x000000000AB30898>)), ('knc', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=4, p=2,\n",
      "           weights='distance'))])\n",
      "\tAccuracy: 0.80167\tPrecision: 0.27327\tRecall: 0.11450\tF1: 0.16138\tF2: 0.12955\n",
      "\tTotal predictions: 12000\tTrue positives:  229\tFalse positives:  609\tFalse negatives: 1771\tTrue negatives: 9391\n",
      "\n",
      "Test Time: 2.726 s\n",
      "\n",
      "K Neigbors Classifier (Ball Tree) ------------------------------------------\n",
      "\n",
      "Search/Fit Time: 31.145 s\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=4, score_func=<function f_classif at 0x000000000AB30898>)), ('knc', KNeighborsClassifier(algorithm='ball_tree', leaf_size=95, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=4,\n",
      "           weights='distance'))])\n",
      "\tAccuracy: 0.82508\tPrecision: 0.25126\tRecall: 0.02500\tF1: 0.04548\tF2: 0.03049\n",
      "\tTotal predictions: 12000\tTrue positives:   50\tFalse positives:  149\tFalse negatives: 1950\tTrue negatives: 9851\n",
      "\n",
      "Test Time: 3.046 s\n",
      "\n",
      "K Neigbors Classifier (KD Tree) ------------------------------------------\n",
      "\n",
      "Search/Fit Time: 30.815 s\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=4, score_func=<function f_classif at 0x000000000AB30898>)), ('knc', KNeighborsClassifier(algorithm='kd_tree', leaf_size=95, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=4,\n",
      "           weights='distance'))])\n",
      "\tAccuracy: 0.82508\tPrecision: 0.25126\tRecall: 0.02500\tF1: 0.04548\tF2: 0.03049\n",
      "\tTotal predictions: 12000\tTrue positives:   50\tFalse positives:  149\tFalse negatives: 1950\tTrue negatives: 9851\n",
      "\n",
      "Test Time: 3.01 s\n",
      "\n",
      "K Neigbors Classifier (Brute) ------------------------------------------\n",
      "\n",
      "Search/Fit Time: 26.888 s\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=4, score_func=<function f_classif at 0x000000000AB30898>)), ('knc', KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=4,\n",
      "           weights='distance'))])\n",
      "\tAccuracy: 0.82508\tPrecision: 0.25126\tRecall: 0.02500\tF1: 0.04548\tF2: 0.03049\n",
      "\tTotal predictions: 12000\tTrue positives:   50\tFalse positives:  149\tFalse negatives: 1950\tTrue negatives: 9851\n",
      "\n",
      "Test Time: 2.269 s\n",
      "\n",
      "Random Forest Classifier ------------------------------------------\n",
      "\n",
      "Search/Fit Time: 114.723 s\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=6, score_func=<function f_classif at 0x000000000AB30898>)), ('rfc', RandomForestClas...imators=16, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      "\tAccuracy: 0.80183\tPrecision: 0.22206\tRecall: 0.07550\tF1: 0.11269\tF2: 0.08698\n",
      "\tTotal predictions: 12000\tTrue positives:  151\tFalse positives:  529\tFalse negatives: 1849\tTrue negatives: 9471\n",
      "\n",
      "Test Time: 54.409 s\n",
      "\n",
      "AdaBoost Classifier ------------------------------------------\n",
      "\n",
      "Search/Fit Time: 49.551 s\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=12, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=3, score_func=<function f_classif at 0x000000000AB30898>)), ('abc', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1,\n",
      "          n_estimators=4, random_state=None))])\n",
      "\tAccuracy: 0.79150\tPrecision: 0.23467\tRecall: 0.11100\tF1: 0.15071\tF2: 0.12408\n",
      "\tTotal predictions: 12000\tTrue positives:  222\tFalse positives:  724\tFalse negatives: 1778\tTrue negatives: 9276\n",
      "\n",
      "Test Time: 9.427 s\n",
      "\n",
      "Total Run Time: 58.978 s\n"
     ]
    }
   ],
   "source": [
    "search_test_classifier(50, 50, 1000, classifiers, dataset, feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gaussian Naive Bayes ------------------------------------------\n",
      "\n",
      "Search/Fit Time: 21.78 s\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=14, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=4, score_func=<function f_classif at 0x000000000AF450B8>)), ('gnb', GaussianNB(priors=None))])\n",
      "\tAccuracy: 0.81158\tPrecision: 0.38441\tRecall: 0.21700\tF1: 0.27740\tF2: 0.23770\n",
      "\tTotal predictions: 12000\tTrue positives:  434\tFalse positives:  695\tFalse negatives: 1566\tTrue negatives: 9305\n",
      "\n",
      "Test Time: 2.235 s\n",
      "\n",
      "Support Vector Machine ------------------------------------------\n",
      "\n",
      "Search/Fit Time: 29.586 s\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=16, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=7, score_func=<function f_classif at 0x000000000AF450B8>)), ('svc', SVC(C=18, cache_...,\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "\tAccuracy: 0.74925\tPrecision: 0.29796\tRecall: 0.37200\tF1: 0.33089\tF2: 0.35439\n",
      "\tTotal predictions: 12000\tTrue positives:  744\tFalse positives: 1753\tFalse negatives: 1256\tTrue negatives: 8247\n",
      "\n",
      "Test Time: 4.921 s\n",
      "\n",
      "Decision Tree Classifier ------------------------------------------\n",
      "\n",
      "Search/Fit Time: 25.097 s\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=8, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=4, score_func=<function f_classif at 0x000000000AF450B8>)), ('dtc', DecisionTreeClass...    min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='random'))])\n",
      "\tAccuracy: 0.79675\tPrecision: 0.33896\tRecall: 0.23100\tF1: 0.27475\tF2: 0.24672\n",
      "\tTotal predictions: 12000\tTrue positives:  462\tFalse positives:  901\tFalse negatives: 1538\tTrue negatives: 9099\n",
      "\n",
      "Test Time: 1.948 s\n",
      "\n",
      "K Neigbors Classifier ------------------------------------------\n",
      "\n",
      "Search/Fit Time: 28.508 s\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=12, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=7, score_func=<function f_classif at 0x000000000AF450B8>)), ('knc', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform'))])\n",
      "\tAccuracy: 0.79708\tPrecision: 0.37774\tRecall: 0.33600\tF1: 0.35565\tF2: 0.34359\n",
      "\tTotal predictions: 12000\tTrue positives:  672\tFalse positives: 1107\tFalse negatives: 1328\tTrue negatives: 8893\n",
      "\n",
      "Test Time: 2.811 s\n",
      "\n",
      "Random Forest Classifier ------------------------------------------\n",
      "\n",
      "Search/Fit Time: 119.065 s\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=14, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=6, score_func=<function f_classif at 0x000000000AF450B8>)), ('rfc', RandomForestClas...imators=20, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      "\tAccuracy: 0.82508\tPrecision: 0.43038\tRecall: 0.15300\tF1: 0.22575\tF2: 0.17564\n",
      "\tTotal predictions: 12000\tTrue positives:  306\tFalse positives:  405\tFalse negatives: 1694\tTrue negatives: 9595\n",
      "\n",
      "Test Time: 62.011 s\n",
      "\n",
      "AdaBoost Classifier ------------------------------------------\n",
      "\n",
      "Search/Fit Time: 49.615 s\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=12, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=8, score_func=<function f_classif at 0x000000000AF450B8>)), ('abc', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1,\n",
      "          n_estimators=9, random_state=None))])\n",
      "\tAccuracy: 0.81658\tPrecision: 0.41783\tRecall: 0.25550\tF1: 0.31710\tF2: 0.27702\n",
      "\tTotal predictions: 12000\tTrue positives:  511\tFalse positives:  712\tFalse negatives: 1489\tTrue negatives: 9288\n",
      "\n",
      "Test Time: 19.165 s\n",
      "\n",
      "Total Run Time: 68.781 s\n"
     ]
    }
   ],
   "source": [
    "search_test_classifier(50, 50, 1000, classifiers, dataset, feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gaussian Naive Bayes ------------------------------------------\n",
      "\n",
      "Search/Fit Time: 18.646 s\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=17, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=3, score_func=<function f_classif at 0x000000000AB30898>)), ('gnb', GaussianNB(priors=None))])\n",
      "\tAccuracy: 0.71800\tPrecision: 0.15254\tRecall: 0.09000\tF1: 0.11321\tF2: 0.09804\n",
      "\tTotal predictions: 5000\tTrue positives:   90\tFalse positives:  500\tFalse negatives:  910\tTrue negatives: 3500\n",
      "\n",
      "Test Time: 1.876 s\n",
      "\n",
      "Support Vector Machine ------------------------------------------\n",
      "\n",
      "Search/Fit Time: 24.477 s\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=16, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=7, score_func=<function f_classif at 0x000000000AB30898>)), ('svc', SVC(C=18, cache_...,\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "\tAccuracy: 0.65880\tPrecision: 0.15927\tRecall: 0.16500\tF1: 0.16208\tF2: 0.16382\n",
      "\tTotal predictions: 5000\tTrue positives:  165\tFalse positives:  871\tFalse negatives:  835\tTrue negatives: 3129\n",
      "\n",
      "Test Time: 1.993 s\n",
      "\n",
      "Decision Tree Classifier ------------------------------------------\n",
      "\n",
      "Search/Fit Time: 23.506 s\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=4, score_func=<function f_classif at 0x000000000AB30898>)), ('dtc', DecisionTreeClas...      min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'))])\n",
      "\tAccuracy: 0.62320\tPrecision: 0.19134\tRecall: 0.27400\tF1: 0.22533\tF2: 0.25221\n",
      "\tTotal predictions: 5000\tTrue positives:  274\tFalse positives: 1158\tFalse negatives:  726\tTrue negatives: 2842\n",
      "\n",
      "Test Time: 1.778 s\n",
      "\n",
      "K Neigbors Classifier ------------------------------------------\n",
      "\n",
      "Search/Fit Time: 23.171 s\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=11, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=5, score_func=<function f_classif at 0x000000000AB30898>)), ('knc', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
      "           weights='uniform'))])\n",
      "\tAccuracy: 0.68320\tPrecision: 0.08166\tRecall: 0.05700\tF1: 0.06714\tF2: 0.06066\n",
      "\tTotal predictions: 5000\tTrue positives:   57\tFalse positives:  641\tFalse negatives:  943\tTrue negatives: 3359\n",
      "\n",
      "Test Time: 2.507 s\n",
      "\n",
      "K Neigbors Classifier (Ball Tree) ------------------------------------------\n",
      "\n",
      "Search/Fit Time: 27.191 s\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=18, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=8, score_func=<function f_classif at 0x000000000AB30898>)), ('knc', KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=12, p=4,\n",
      "           weights='distance'))])\n",
      "\tAccuracy: 0.75020\tPrecision: 0.04727\tRecall: 0.01300\tF1: 0.02039\tF2: 0.01520\n",
      "\tTotal predictions: 5000\tTrue positives:   13\tFalse positives:  262\tFalse negatives:  987\tTrue negatives: 3738\n",
      "\n",
      "Test Time: 2.696 s\n",
      "\n",
      "K Neigbors Classifier (KD Tree) ------------------------------------------\n",
      "\n",
      "Search/Fit Time: 27.461 s\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=18, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=8, score_func=<function f_classif at 0x000000000AB30898>)), ('knc', KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=12, p=4,\n",
      "           weights='distance'))])\n",
      "\tAccuracy: 0.75020\tPrecision: 0.04727\tRecall: 0.01300\tF1: 0.02039\tF2: 0.01520\n",
      "\tTotal predictions: 5000\tTrue positives:   13\tFalse positives:  262\tFalse negatives:  987\tTrue negatives: 3738\n",
      "\n",
      "Test Time: 2.654 s\n",
      "\n",
      "K Neigbors Classifier (Brute) ------------------------------------------\n",
      "\n",
      "Search/Fit Time: 22.959 s\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=18, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=8, score_func=<function f_classif at 0x000000000AB30898>)), ('knc', KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=12, p=4,\n",
      "           weights='distance'))])\n",
      "\tAccuracy: 0.75020\tPrecision: 0.04727\tRecall: 0.01300\tF1: 0.02039\tF2: 0.01520\n",
      "\tTotal predictions: 5000\tTrue positives:   13\tFalse positives:  262\tFalse negatives:  987\tTrue negatives: 3738\n",
      "\n",
      "Test Time: 1.983 s\n",
      "\n",
      "Random Forest Classifier ------------------------------------------\n",
      "\n",
      "Search/Fit Time: 115.267 s\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=13, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=2, score_func=<function f_classif at 0x000000000AB30898>)), ('rfc', RandomForestClas...imators=19, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      "\tAccuracy: 0.65720\tPrecision: 0.17188\tRecall: 0.18700\tF1: 0.17912\tF2: 0.18377\n",
      "\tTotal predictions: 5000\tTrue positives:  187\tFalse positives:  901\tFalse negatives:  813\tTrue negatives: 3099\n",
      "\n",
      "Test Time: 59.674 s\n",
      "\n",
      "AdaBoost Classifier ------------------------------------------\n",
      "\n",
      "Search/Fit Time: 41.852 s\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=16, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=3, score_func=<function f_classif at 0x000000000AB30898>)), ('abc', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1,\n",
      "          n_estimators=2, random_state=None))])\n",
      "\tAccuracy: 0.67360\tPrecision: 0.17951\tRecall: 0.17700\tF1: 0.17825\tF2: 0.17750\n",
      "\tTotal predictions: 5000\tTrue positives:  177\tFalse positives:  809\tFalse negatives:  823\tTrue negatives: 3191\n",
      "\n",
      "Test Time: 5.18 s\n",
      "\n",
      "Total Run Time: 47.032 s\n"
     ]
    }
   ],
   "source": [
    "search_test_classifier(50, 50, 1000, classifiers, dataset, feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_classifier(\"Gaussian Naive Bayes\", classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_classifier(\"Support Vector Machine\", classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_classifier(\"Decision Tree Classifier\", classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove_classifier(\"K Neigbors Classifier\", classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_classifier(\"Random Forest Classifier\", classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_classifier(\"AdaBoost Classifier\", classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = []\n",
    "pipes = []\n",
    "params = []\n",
    "\n",
    "names.append('K Neigbors Classifier (Ball Tree)')\n",
    "pipes.append(('knc', KNeighborsClassifier()))\n",
    "params.append({\n",
    "        'knc__algorithm':['ball_tree'],\n",
    "        'knc__leaf_size':randint(5,100),\n",
    "        'knc__p':randint(1,5),\n",
    "        'knc__n_neighbors':randint(1,26), \n",
    "        'knc__weights':('uniform', 'distance')\n",
    "    })\n",
    "\n",
    "names.append('K Neigbors Classifier (KD Tree)')\n",
    "pipes.append(('knc', KNeighborsClassifier()))\n",
    "params.append({\n",
    "        'knc__algorithm':['kd_tree'],\n",
    "        'knc__leaf_size':randint(5,100),\n",
    "        'knc__p':randint(1,5),\n",
    "        'knc__n_neighbors':randint(1,26), \n",
    "        'knc__weights':('uniform', 'distance')\n",
    "    })\n",
    "\n",
    "names.append('K Neigbors Classifier (Brute)')\n",
    "pipes.append(('knc', KNeighborsClassifier()))\n",
    "params.append({\n",
    "        'knc__algorithm':['brute'],\n",
    "        'knc__p':randint(1,5),\n",
    "        'knc__n_neighbors':randint(1,26), \n",
    "        'knc__weights':('uniform', 'distance')\n",
    "    })\n",
    "\n",
    "pipelines = []\n",
    "parameters = []\n",
    "\n",
    "for i in range(0, len(pipes)):\n",
    "    pipelines.append(Pipeline(steps=[x for x in pipe.steps]))\n",
    "    pipelines[i].steps.append(pipes[i])\n",
    "    parameters.append(param.copy())\n",
    "    parameters[i].update(params[i])\n",
    "    \n",
    "classifiers = []\n",
    "classifiers.extend((names, pipelines, parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_test_classifier(50, 50, 1000, classifiers, dataset, feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_classifier(\"K Neigbors Classifier (KD Tree)\", classifiers)\n",
    "remove_classifier(\"K Neigbors Classifier (Brute)\", classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K Neigbors Classifier (Ball Tree) ------------------------------------------\n",
      "\n",
      "Search/Fit Time: 1781.063 s\n",
      "\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=11, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('skb', SelectKBest(k=6, score_func=<function f_classif at 0x000000000AF450B8>)), ('knc', KNeighborsClassifier(algorithm='ball_tree', leaf_size=48, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
      "           weights='distance'))])\n",
      "\tAccuracy: 0.79758\tPrecision: 0.38259\tRecall: 0.34950\tF1: 0.36530\tF2: 0.35565\n",
      "\tTotal predictions: 12000\tTrue positives:  699\tFalse positives: 1128\tFalse negatives: 1301\tTrue negatives: 8872\n",
      "\n",
      "Test Time: 3.887 s\n",
      "\n",
      "Total Run Time: 1784.951 s\n"
     ]
    }
   ],
   "source": [
    "search_test_classifier(500, 200, 1000, classifiers, dataset, feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest takes far too long to run and test so we will remove it and increase the number of iterations and folds and re-test the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remove_classifier(\"Random Forest Classifier\", classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from the second itteration were that 3 of the 5 remaining classifiers (Gaussian Naive Bayes, Support Vector Machine, and AdaBoost) had F1 scores above 0.3. While SVM and AdaBoost did not pass on both recall and precision, we will try to run more iteration of the random search on these classifiers and see if there is any adjustments on parameters that we can make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_classifier(\"Decision Tree Classifier\", classifiers)\n",
    "remove_classifier(\"K Neigbors Classifier\", classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_test_classifier(200, 200, 1000, classifiers, dataset, feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_test_classifier(200, 500, 1000, classifiers, dataset, feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After testing the remaining classifiers with a higher number of parameter iterations and validation folds it can be seen that the Gaussian Naive Bayes classifier remains the classifer with the highest F1 score while having both percision and recall above 0.3. This being said, there could be better classifier/parameter combinations available that we not observed in this code due to the random search and/or the ranges for the random searches that were set in the parameter initalizations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('pca', PCA()),\n",
    "        ('skb', SelectKBest()),\n",
    "        ('gnb', GaussianNB())\n",
    "    ])\n",
    "param = [{'skb__k':range(1,9),'pca__n_components':range(8,19)},\n",
    "         {'skb__k':range(1,8),'pca__n_components':[7]},\n",
    "         {'skb__k':range(1,7),'pca__n_components':[6]},\n",
    "         {'skb__k':range(1,6),'pca__n_components':[5]},\n",
    "         {'skb__k':range(1,5),'pca__n_components':[4]},\n",
    "         {'skb__k':range(1,4),'pca__n_components':[3]},\n",
    "         {'skb__k':range(1,3),'pca__n_components':[2]}]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=100, random_state=42, test_size=0.3)\n",
    "gs = GridSearchCV(pipe, param, scoring='f1', cv=cv)\n",
    "gs.fit(features_df, labels_df)\n",
    "clf = gs.best_estimator_\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_classifier(clf, dataset, feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"THE TRAVEL AGENCY IN THE PARK\" \n",
    "parameters = {'tree__criterion': ('gini','entropy'),\n",
    "              'tree__splitter':('best','random'),\n",
    "              'tree__min_samples_split':[2, 10, 20],\n",
    "                'tree__max_depth':[10,15,20,25,30],\n",
    "                'tree__max_leaf_nodes':[5,10,30]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KNeighborsClassifier "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
